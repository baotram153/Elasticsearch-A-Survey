{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c3d2dc",
   "metadata": {},
   "source": [
    "# Part 2: Query Processing & Query Rewrite demos\n",
    "Show how Elasticsearch rewrites queries/aggregations using real radiology text and DICOM metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672d1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84549739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import current working dir to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "\n",
    "# declare constants\n",
    "ES_HOST = \"http://localhost:9200\"\n",
    "\n",
    "TEXT_INDEX = \"radiology_text\"\n",
    "VECTOR_INDEX = \"radiology_vector\"\n",
    "\n",
    "TEXT_DATA_PATH = \"../../data/text/Radiologists Report.xlsx\"\n",
    "IMAGE_DATA_DIR = \"../../data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66db0f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n"
     ]
    }
   ],
   "source": [
    "# connect to Elasticsearch\n",
    "es = Elasticsearch(ES_HOST)\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61f3d7",
   "metadata": {},
   "source": [
    "## 1. Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4781fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import current working dir to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "\n",
    "# declare constants\n",
    "ES_HOST = \"http://localhost:9200\"\n",
    "\n",
    "TEXT_INDEX = \"radiology_text\"\n",
    "DOC_INDEX = \"radiology_doc\"\n",
    "VECTOR_INDEX = \"radiology_vector\"\n",
    "\n",
    "TEXT_DATA_PATH = \"../../data/text/Radiologists Report.xlsx\"\n",
    "IMAGE_DATA_DIR = \"../../data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd91d2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n"
     ]
    }
   ],
   "source": [
    "# connect to Elasticsearch\n",
    "es = Elasticsearch(ES_HOST)\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadc8bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating radiology_text to enforce shard/replica settings\n",
      "Created radiology_text with 2 shards / 1 replica\n",
      "[{'index': {'_index': 'radiology_text', '_id': '18', 'status': 400, 'error': {'type': 'document_parsing_exception', 'reason': '[1:18] failed to parse: [1:39] Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (byte[])\"{\"patient_id\":18,\"clinician_notes\":NaN}\"; line: 1, column: 39]', 'caused_by': {'type': 'x_content_parse_exception', 'reason': '[1:39] Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (byte[])\"{\"patient_id\":18,\"clinician_notes\":NaN}\"; line: 1, column: 39]', 'caused_by': {'type': 'json_parse_exception', 'reason': 'Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (byte[])\"{\"patient_id\":18,\"clinician_notes\":NaN}\"; line: 1, column: 39]'}}}, 'data': {'patient_id': 18, 'clinician_notes': nan}}}, {'index': {'_index': 'radiology_text', '_id': '28', 'status': 400, 'error': {'type': 'document_parsing_exception', 'reason': '[1:18] failed to parse: [1:39] Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (byte[])\"{\"patient_id\":28,\"clinician_notes\":NaN}\"; line: 1, column: 39]', 'caused_by': {'type': 'illegal_argument_exception', 'reason': '[1:39] Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (byte[])\"{\"patient_id\":28,\"clinician_notes\":NaN}\"; line: 1, column: 39]', 'caused_by': {'type': 'i_o_exception', 'reason': 'Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (byte[])\"{\"patient_id\":28,\"clinician_notes\":NaN}\"; line: 1, column: 39]'}}}, 'data': {'patient_id': 28, 'clinician_notes': nan}}}]\n",
      "Indexed 575 text docs\n"
     ]
    }
   ],
   "source": [
    "# ensure radiology_text exists with 2 primary shards and 1 replica\n",
    "def ensure_text_index():\n",
    "    if es.indices.exists(index=TEXT_INDEX):\n",
    "        print(f'Recreating {TEXT_INDEX} to enforce shard/replica settings')\n",
    "        es.indices.delete(index=TEXT_INDEX)\n",
    "\n",
    "    settings = {\n",
    "        'settings': {\n",
    "            'number_of_shards': 2,\n",
    "            'number_of_replicas': 1\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"patient_id\": {\n",
    "                    \"type\": \"keyword\",\n",
    "                    \"null_value\": \"NULL_PATIENT\"\n",
    "                },\n",
    "                \"clinician_notes\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"fields\": {\n",
    "                        \"keyword\": {\n",
    "                        \"type\": \"keyword\",\n",
    "                        \"ignore_above\": 256,\n",
    "                        \"null_value\": \"NULL_NOTE\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=TEXT_INDEX, body=settings)\n",
    "    print(f'Created {TEXT_INDEX} with 2 shards / 1 replica')\n",
    "\n",
    "    df = pd.read_excel(TEXT_DATA_PATH)\n",
    "    actions = []\n",
    "    for _, row in df.iterrows():\n",
    "        actions.append({\n",
    "            '_index': TEXT_INDEX,\n",
    "            '_id': str(row['Patient ID']),\n",
    "            '_source': {\n",
    "                'patient_id': row['Patient ID'],\n",
    "                'clinician_notes': row[\"Clinician's Notes\"]\n",
    "            }\n",
    "        })\n",
    "    try:\n",
    "        helpers.bulk(es, actions)\n",
    "    except helpers.BulkIndexError as e:\n",
    "        print(e.errors[:2])  # inspect the reason\n",
    "\n",
    "    print(f'Indexed {len(actions)} text docs')\n",
    "\n",
    "ensure_text_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00d94261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created radiology_doc\n",
      "Indexed 48345 DICOM metadata docs\n"
     ]
    }
   ],
   "source": [
    "# ensure DICOM metadata index exists with up to 1000 docs for range/BKD demo\n",
    "from itertools import islice\n",
    "from helpers.ima_loader import load_dicom, get_metadata\n",
    "\n",
    "def iter_dicom_paths(root):\n",
    "    for dirpath, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".ima\", \".dcm\")):\n",
    "                yield os.path.join(dirpath, f)\n",
    "\n",
    "def ensure_dicom_index(limit=50000):\n",
    "    if es.indices.exists(index=DOC_INDEX):\n",
    "        count = es.count(index=DOC_INDEX)['count']\n",
    "        if count >= limit:\n",
    "            print(f'{DOC_INDEX} already has {count} docs')\n",
    "            return\n",
    "        es.indices.delete(index=DOC_INDEX)\n",
    "\n",
    "    mapping = {\n",
    "        'mappings': {\n",
    "            'properties': {\n",
    "                'doc_id': {'type': 'keyword'},\n",
    "                'patient_id': {'type': 'keyword'},\n",
    "                'series_description': {\n",
    "                    'type': 'text',\n",
    "                    'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}\n",
    "                },\n",
    "                'slice_thickness': {'type': 'double'},\n",
    "                'spacing_between_slices': {'type': 'double'},\n",
    "                'rows': {'type': 'integer'},\n",
    "                'columns': {'type': 'integer'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=DOC_INDEX, body=mapping)\n",
    "    print(f'Created {DOC_INDEX}')\n",
    "\n",
    "    sample_paths = list(islice(iter_dicom_paths(IMAGE_DATA_DIR), limit))\n",
    "    docs = []\n",
    "    for path in sample_paths:\n",
    "        dicom = load_dicom(path)\n",
    "        meta = get_metadata(dicom)\n",
    "        doc = {\n",
    "            'doc_id': f\"{meta.get('PatientID', 'unknown')}_{os.path.basename(path)}\",\n",
    "            'patient_id': meta.get('PatientID'),\n",
    "            'series_description': meta.get('SeriesDescription'),\n",
    "            'slice_thickness': float(meta.get('SliceThickness', 0) or 0),\n",
    "            'spacing_between_slices': float(meta.get('SpacingBetweenSlices', 0) or 0),\n",
    "            'rows': int(meta.get('Rows', 0) or 0),\n",
    "            'columns': int(meta.get('Columns', 0) or 0)\n",
    "        }\n",
    "        docs.append(doc)\n",
    "\n",
    "    actions = [{'_index': DOC_INDEX, '_id': d['doc_id'], '_source': d} for d in docs]\n",
    "    if actions:\n",
    "        helpers.bulk(es, actions)\n",
    "        print(f'Indexed {len(actions)} DICOM metadata docs')\n",
    "    else:\n",
    "        print('No DICOM files found to index')\n",
    "\n",
    "ensure_dicom_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "995c2800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radiology_doc has 43351 docs\n"
     ]
    }
   ],
   "source": [
    "# check number of docs in DOC_INDEX\n",
    "count = es.count(index=DOC_INDEX)['count']\n",
    "print(f'{DOC_INDEX} has {count} docs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a81a54",
   "metadata": {},
   "source": [
    "### Collect doc ids for explain\n",
    "We'll reuse the indexed docs so explain has concrete IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88968f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fetch a text doc: list index out of range\n",
      "DICOM_DOC_ID: unknown_LOCALIZER_0_0001_001.ima\n"
     ]
    }
   ],
   "source": [
    "text_doc_id = None\n",
    "dicom_doc_id = None\n",
    "\n",
    "try:\n",
    "    res_text = es.search(index=TEXT_INDEX, size=1, _source=True)\n",
    "    text_doc_id = res_text['hits']['hits'][0]['_id']\n",
    "    print('TEXT_DOC_ID:', text_doc_id)\n",
    "except Exception as e:\n",
    "    print('Could not fetch a text doc:', e)\n",
    "\n",
    "try:\n",
    "    res_dicom = es.search(index=DOC_INDEX, size=1, _source=True)\n",
    "    dicom_doc_id = res_dicom['hits']['hits'][0]['_id']\n",
    "    print('DICOM_DOC_ID:', dicom_doc_id)\n",
    "except Exception as e:\n",
    "    print('Could not fetch a DICOM doc:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae0697",
   "metadata": {},
   "source": [
    "## 2. Query Rewriting Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93aaccb",
   "metadata": {},
   "source": [
    "### 1. Match query rewrite (inverted index)\n",
    "Explain shows Lucene rewriting match into BooleanQuery of analyzed terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6678cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'explanation': 'clinician_notes:disc clinician_notes:bulge',\n",
      "  'index': 'radiology_text',\n",
      "  'valid': True}]\n"
     ]
    }
   ],
   "source": [
    "match_query = {'query': {'match': {'clinician_notes': 'disc bulge'}}}\n",
    "match_exp = es.indices.validate_query(index=TEXT_INDEX, body=match_query, explain=True, rewrite=True)\n",
    "pprint(match_exp['explanations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f8643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'explanation': '+clinician_notes:disc +clinician_notes:bulge',\n",
      "  'index': 'radiology_text',\n",
      "  'valid': True}]\n"
     ]
    }
   ],
   "source": [
    "match_query = {'query': \n",
    "                    {'match': \n",
    "                        {'clinician_notes': \n",
    "                            {\n",
    "                                'query': 'disc bulge',\n",
    "                                'operator': 'and'\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "match_exp = es.indices.validate_query(index=TEXT_INDEX, body=match_query, explain=True, rewrite=True)\n",
    "pprint(match_exp['explanations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561c285",
   "metadata": {},
   "source": [
    "### 2. Range query rewrite (BKD)\n",
    "Numeric ranges are served by BKD trees; explain shows the rewritten range clause.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeda62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum slice_thickness: 4.0\n"
     ]
    }
   ],
   "source": [
    "# get min value of slice_thickness\n",
    "response = es.search(\n",
    "    index=DOC_INDEX,\n",
    "    body={\n",
    "        \"size\": 0,\n",
    "        \"aggs\": {\n",
    "            \"min_slice_thickness\": {\n",
    "                \"min\": {\n",
    "                    \"field\": \"slice_thickness\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(\"Minimum slice_thickness:\", response['aggregations']['min_slice_thickness']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda34c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'explanation': 'IndexOrDocValuesQuery(indexQuery=slice_thickness:[9.0 TO '\n",
      "                 'Infinity], dvQuery=slice_thickness:[4621256167635550208 TO '\n",
      "                 '9218868437227405312])',\n",
      "  'index': 'radiology_doc',\n",
      "  'valid': True}]\n"
     ]
    }
   ],
   "source": [
    "if dicom_doc_id:\n",
    "    range_query = {'query': {'range': {'slice_thickness': {'gte': 9.0}}}}\n",
    "    range_exp = es.indices.validate_query(index=DOC_INDEX, body=range_query, explain=True, rewrite=True)\n",
    "    pprint(range_exp['explanations'])\n",
    "else:\n",
    "    print('No DICOM_DOC_ID available to run explain')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b16aa",
   "metadata": {},
   "source": [
    "### 3. Aggregations require keyword/doc_values\n",
    "Terms agg on a text field errors; switching to `.keyword` succeeds (doc values).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bf341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agg on text -> error (needs .keyword): BadRequestError(400, 'search_phase_execution_exception', 'Fielddata is disabled on [clinician_notes] in [radiology_text]. Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [clinician_notes] in order to load field data by uninverting the inverted index. Note that this can use significant memory.', Fielddata is disabled on [clinician_notes] in [radiology_text]. Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [clinician_notes] in order to load field data by uninverting the inverted index. Note that this can use significant memory.)\n"
     ]
    }
   ],
   "source": [
    "agg_text = {'size': 0, 'aggs': {'by_note': {'terms': {'field': 'clinician_notes'}}}}\n",
    "try:\n",
    "    es.search(index=TEXT_INDEX, body=agg_text)\n",
    "except Exception as e:\n",
    "    print('Agg on text -> error (needs .keyword):', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43edccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "agg_keyword = {'size': 0, 'aggs': {'by_note': {'terms': {'field': 'clinician_notes.keyword'}}}}\n",
    "try:\n",
    "    agg_res = es.search(index=TEXT_INDEX, body=agg_keyword)\n",
    "    pprint(agg_res['aggregations']['by_note']['buckets'][:3])\n",
    "except Exception as e:\n",
    "    print('Agg on .keyword failed (check mapping):', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a0a69",
   "metadata": {},
   "source": [
    "### 4. Wildcard field expansion\n",
    "Use validate_query with rewrite to see `clin*` expanded to actual fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5c390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'explanation': 'MatchNoDocsQuery(\"unmapped fields []\")',\n",
      "  'index': 'radiology_text',\n",
      "  'valid': True}]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validation = es.indices.validate_query(\n",
    "        index=TEXT_INDEX,\n",
    "        body={'query': {'multi_match': {'query': 'disc', 'fields': ['clin*']}}},\n",
    "        explain=True,\n",
    "        rewrite=True\n",
    "    )\n",
    "    pprint(validation.get('explanations', [])[:2])\n",
    "except Exception as e:\n",
    "    print('Wildcard validation failed:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e88e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['clinician_notes.keyword', 'clinician_notes'])\n"
     ]
    }
   ],
   "source": [
    "response = es.indices.get_field_mapping(index=TEXT_INDEX, fields='clin*')\n",
    "pprint(response['radiology_text']['mappings'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f7266",
   "metadata": {},
   "source": [
    "## 2. Distributed execution â€” Query vs Fetch phases\n",
    "Use the profile API to see which shards answered, how the query was rewritten/executed, and how fetch loads _source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3940127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creation_date': '1765373383241',\n",
      " 'number_of_replicas': '1',\n",
      " 'number_of_shards': '2',\n",
      " 'provided_name': 'radiology_text',\n",
      " 'routing': {'allocation': {'include': {'_tier_preference': 'data_content'}}},\n",
      " 'uuid': 'V95DGmJiTumv1dxH_Z6_aQ',\n",
      " 'version': {'created': '9039001'}}\n"
     ]
    }
   ],
   "source": [
    "# check number of primary / replica shards\n",
    "response = es.indices.get_settings(index=TEXT_INDEX)\n",
    "pprint(response[TEXT_INDEX]['settings']['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45783fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shard</th>\n",
       "      <th>docs</th>\n",
       "      <th>volume_kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>76.8kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>62kb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shard docs volume_kb\n",
       "0     0  257    76.8kb\n",
       "1     1  192      62kb"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see number of docs in each primary shard\n",
    "response = es.cat.shards(index=TEXT_INDEX, format='json')\n",
    "shard_rows = []\n",
    "for shard in response:\n",
    "    if shard['prirep'] != 'p':\n",
    "        continue\n",
    "    shard_rows.append(\n",
    "        {'shard': shard['shard'], 'docs': shard['docs'], 'volume_kb': shard['store']}\n",
    "    )\n",
    "pd.DataFrame(shard_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796a0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits: {'value': 206, 'relation': 'eq'}\n",
      "Shards involved: {'total': 2, 'successful': 2, 'skipped': 0, 'failed': 0}\n",
      "Profile (truncated to first shard):\n",
      "{\n",
      "  \"id\": \"[BZ2TnfIhQXCJr3__UCYqDA][radiology_text][1]\",\n",
      "  \"node_id\": \"BZ2TnfIhQXCJr3__UCYqDA\",\n",
      "  \"shard_id\": 1,\n",
      "  \"index\": \"radiology_text\",\n",
      "  \"cluster\": \"(local)\",\n",
      "  \"searches\": [\n",
      "    {\n",
      "      \"query\": [\n",
      "        {\n",
      "          \"type\": \"BooleanQuery\",\n",
      "          \"description\": \"clinician_notes:neural clinician_notes:canal\",\n",
      "          \"time_in_nanos\": 2174470,\n",
      "          \"breakdown\": {\n",
      "            \"set_min_competitive_score_count\": 0,\n",
      "            \"match_count\": 89,\n",
      "            \"shallow_advance_count\": 0,\n",
      "            \"set_min_competitive_score\": 0,\n",
      "            \"next_doc\": 302432,\n",
      "            \"match\": 26034,\n",
      "            \"score_count\": 89,\n",
      "            \"next_doc_count\": 90,\n",
      "            \"compute_max_score_count\": 0,\n",
      "            \"compute_max_score\": 0,\n",
      "            \"advance\": 0,\n",
      "            \"advance_count\": 0,\n",
      "            \"count_weight_count\": 0,\n",
      "            \"score\": 4566,\n",
      "            \"build_scorer_count\": 2,\n",
      "            \"create_weight\": 678425,\n",
      "            \"shallow_advance\": 0,\n",
      "            \"count_weight\": 0,\n",
      "            \"create_weight_count\": 1,\n",
      "            \"build_scorer\": 1163013\n",
      "          },\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"type\": \"TermQuery\",\n",
      "              \"description\": \"clinician_notes:neural\",\n",
      "              \"time_in_nanos\": 1187148,\n",
      "              \"breakdown\": {\n",
      "                \"set_min_competitive_score_count\": 0,\n",
      "                \"match_count\": 0,\n",
      "                \"shallow_advance_count\": 2,\n",
      "                \"set_min_competitive_score\": 0,\n",
      "                \"next_doc\": 0,\n",
      "                \"match\": 0,\n",
      "                \"score_count\": 41,\n",
      "                \"next_doc_count\": 0,\n",
      "                \"compute_max_score_count\": 2,\n",
      "                \"compute_max_score\": 8125,\n",
      "                \"advance\": 30377,\n",
      "                \"advance_count\": 42,\n",
      "                \"count_weight_count\": 0,\n",
      "                \"score\": 2274,\n",
      "                \"build_scorer_count\": 3,\n",
      "                \"create_weight\": 474740,\n",
      "                \"shallow_advance\": 4168,\n",
      "                \"count_weight\": 0,\n",
      "    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_929572/1815081088.py:2: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  profile_res = es.search(\n"
     ]
    }
   ],
   "source": [
    "# profile a match query to see shard-level query/fetch phases\n",
    "profile_res = es.search(\n",
    "    index=TEXT_INDEX,\n",
    "    body={\n",
    "        'profile': True,\n",
    "        'query': {'match': {'clinician_notes': 'neural canal'}}\n",
    "    },\n",
    "    size=3\n",
    ")\n",
    "\n",
    "print('Total hits:', profile_res['hits']['total'])\n",
    "print('Shards involved:', profile_res['_shards'])\n",
    "\n",
    "import json as _json\n",
    "print('Profile (truncated to first shard):')\n",
    "print(_json.dumps(profile_res['profile']['shards'][0], indent=2)[:2000], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17066bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shard</th>\n",
       "      <th>query_time_ms</th>\n",
       "      <th>fetch_time_ms</th>\n",
       "      <th>query_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BZ2TnfIhQXCJr3__UCYqDA][radiology_text][1]</td>\n",
       "      <td>2.17447</td>\n",
       "      <td>1.179043</td>\n",
       "      <td>clinician_notes:neural clinician_notes:canal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[K3KnPcSGRIeEfmMhbRH35w][radiology_text][0]</td>\n",
       "      <td>1.52026</td>\n",
       "      <td>0.911226</td>\n",
       "      <td>clinician_notes:neural clinician_notes:canal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         shard  query_time_ms  fetch_time_ms  \\\n",
       "0  [BZ2TnfIhQXCJr3__UCYqDA][radiology_text][1]        2.17447       1.179043   \n",
       "1  [K3KnPcSGRIeEfmMhbRH35w][radiology_text][0]        1.52026       0.911226   \n",
       "\n",
       "                              query_description  \n",
       "0  clinician_notes:neural clinician_notes:canal  \n",
       "1  clinician_notes:neural clinician_notes:canal  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize query vs fetch per shard\n",
    "shard_rows = []\n",
    "for shard in profile_res['profile']['shards']:\n",
    "    sid = shard['id']\n",
    "    searches = shard['searches'][0]\n",
    "    query_time = searches['query'][0]['time_in_nanos']\n",
    "    fetch_time = shard['fetch']['time_in_nanos']\n",
    "    shard_rows.append({\n",
    "        'shard': sid,\n",
    "        'query_time_ms': query_time / 1e6,\n",
    "        'fetch_time_ms': fetch_time / 1e6,\n",
    "        'query_description': searches['query'][0]['description']\n",
    "    })\n",
    "pd.DataFrame(shard_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18ff3e",
   "metadata": {},
   "source": [
    "## 3. Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Request cache demo ===\n",
      "Uncached (mean): 0.0014 +- 0.0008 s\n",
      "Cached (mean):   0.001 +- 0.0004 s\n"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "import statistics\n",
    "\n",
    "agg_query = {\n",
    "    \"size\": 0,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"filter\": [\n",
    "                {\"term\": {\"body_part_examined\": \"L-SPINE\"}},\n",
    "                {\"range\": {\"slice_thickness\": {\"gte\": 9}}},\n",
    "                {\"range\": {\"spacing_between_slices\": {\"gte\": 15}}},\n",
    "                {\"exists\": {\"field\": \"patient_id\"}}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"aggs\": {\n",
    "        \"by_part\": {\n",
    "            \"terms\": {\"field\": \"body_part_examined.keyword\", \"size\": 10},\n",
    "            \"aggs\": {\n",
    "                \"slice_stats\": {\"stats\": {\"field\": \"slice_thickness\"}},\n",
    "                \"slice_percentiles\": {\"percentiles\": {\"field\": \"slice_thickness\", \"percents\": [5, 25, 50, 75, 95]}},\n",
    "                \"top_example\": {\"top_hits\": {\"size\": 1, \"_source\": {\"includes\": [\"patient_id\", \"slice_thickness\", \"spacing_between_slices\"]}}}\n",
    "            }\n",
    "        },\n",
    "        \"thickness_hist\": {\n",
    "            \"histogram\": {\"field\": \"slice_thickness\", \"interval\": 0.1, \"min_doc_count\": 1},\n",
    "            \"aggs\": {\"spacing_avg\": {\"avg\": {\"field\": \"spacing_between_slices\"}}}\n",
    "        },\n",
    "        \"spacing_hist\": {\n",
    "            \"histogram\": {\"field\": \"spacing_between_slices\", \"interval\": 0.5, \"min_doc_count\": 1},\n",
    "            \"aggs\": {\"thickness_avg\": {\"avg\": {\"field\": \"slice_thickness\"}}}\n",
    "        },\n",
    "        \"patient_cardinality\": {\"cardinality\": {\"field\": \"patient_id\"}},\n",
    "    }\n",
    "}\n",
    "def timed_many(body, n=10, **kwargs):\n",
    "    times = []\n",
    "    for _ in range(n):\n",
    "        t0 = time.time()\n",
    "        es.search(index=DOC_INDEX, body=body, **kwargs)\n",
    "        times.append(time.time() - t0)\n",
    "    return statistics.mean(times), statistics.stdev(times)\n",
    "\n",
    "# clear all cache of index before experiment\n",
    "es.indices.clear_cache()\n",
    "\n",
    "print(\"=== Request cache demo ===\")\n",
    "mean_uncached, std_uncached = timed_many(agg_query, n=100, request_cache=False)\n",
    "print(\"Uncached (mean):\", round(mean_uncached, 4), \"+-\", round(std_uncached, 4), \"s\")\n",
    "    \n",
    "mean_cached, std_cached = timed_many(agg_query, n=100, request_cache=True)\n",
    "print(\"Cached (mean):  \", round(mean_cached, 4), \"+-\", round(std_cached, 4), \"s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbms-assignment (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
