{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e0da31",
   "metadata": {},
   "source": [
    "# Part 1: Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2cf050",
   "metadata": {},
   "source": [
    "## 0. Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f6a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d778d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import current working dir to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "\n",
    "# declare constants\n",
    "ES_HOST = \"http://localhost:9200\"\n",
    "\n",
    "TEXT_INDEX = \"radiology_text\"\n",
    "VECTOR_INDEX = \"radiology_vector\"\n",
    "\n",
    "TEXT_DATA_PATH = \"../../data/text/Radiologists Report.xlsx\"\n",
    "IMAGE_DATA_DIR = \"../../data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0204eab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch!\n"
     ]
    }
   ],
   "source": [
    "# connect to Elasticsearch\n",
    "es = Elasticsearch(ES_HOST)\n",
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7d74f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing index: radiology_text\n",
      "Created new index: radiology_text\n"
     ]
    }
   ],
   "source": [
    "# delete existed index and create new one\n",
    "if es.indices.exists(index=TEXT_INDEX):\n",
    "    es.indices.delete(index=TEXT_INDEX)\n",
    "    print(f\"Deleted existing index: {TEXT_INDEX}\")\n",
    "es.indices.create(index=TEXT_INDEX)\n",
    "print(f\"Created new index: {TEXT_INDEX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907dee3",
   "metadata": {},
   "source": [
    "## 1. Inverted Index for Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9379c",
   "metadata": {},
   "source": [
    "- An inverted index is a data structure used for fast full-text search. Instead of mapping documents -> words (forward index), it maps words -> documents containing those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c30ca7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Clinician's Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>L4-5: degenerative annular disc bulge is noted more to the left side compressing thecal sac, compressing left nerve root and narrowing right neural foramen. // Evidence of hyperintense signal within the annulus fibrosus at left paramedian/posterolateral area which probably represents a torn annulus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No evidence of disc herniation.\\nNo significant thecal sac or nerve root compression noted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LSS MRI\\nFeatures of muscle spasm.\\nsmall central  disc protrusion noted at L5-S1 level abutting the thecal sac.\\nno significant thecal  sac or nerve root compression noted.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  \\\n",
       "0           1   \n",
       "1           2   \n",
       "2           3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                              Clinician's Notes  \n",
       "0  L4-5: degenerative annular disc bulge is noted more to the left side compressing thecal sac, compressing left nerve root and narrowing right neural foramen. // Evidence of hyperintense signal within the annulus fibrosus at left paramedian/posterolateral area which probably represents a torn annulus.  \n",
       "1                                                                                                                                                                                                                   No evidence of disc herniation.\\nNo significant thecal sac or nerve root compression noted.  \n",
       "2                                                                                                                                LSS MRI\\nFeatures of muscle spasm.\\nsmall central  disc protrusion noted at L5-S1 level abutting the thecal sac.\\nno significant thecal  sac or nerve root compression noted.   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read 3 first rows of the text data\n",
    "text_data = pd.read_excel(TEXT_DATA_PATH)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "text_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f36b1b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 tokens using 'whitespace' analyzer:\n",
      "- L4-5:\n",
      "- degenerative\n",
      "- annular\n",
      "- disc\n",
      "- bulge\n",
      "- is\n",
      "- noted\n",
      "- more\n",
      "- to\n",
      "- the\n"
     ]
    }
   ],
   "source": [
    "# demo es analyzer\n",
    "body = text_data.loc[0, 'Clinician\\'s Notes']\n",
    "analyzer = \"whitespace\"    # can try \"whitespace\", \"simple, \"keyword\"\n",
    "\n",
    "analyze_result = es.indices.analyze(\n",
    "    index=TEXT_INDEX,\n",
    "    body={\n",
    "        \"analyzer\": analyzer,\n",
    "        \"text\": body\n",
    "    }\n",
    ")\n",
    "\n",
    "analyzer_tokens = [token_info['token'] for token_info in analyze_result['tokens']]\n",
    "print(f\"First 10 tokens using '{analyzer}' analyzer:\")\n",
    "for i in range(min(10, len(analyzer_tokens))):\n",
    "    print(f\"- {analyzer_tokens[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130555e7",
   "metadata": {},
   "source": [
    "- A small example of an inverted index for our radiology reports might look like this:\n",
    "\n",
    "    | Term         | Document IDs |\n",
    "    |--------------|--------------|\n",
    "    | disc         | [1, 2, 3]    |\n",
    "    | thecal       | [1, 2, 3]    |\n",
    "    | degenerative | [1]          |\n",
    "    | herniation   | [2]          |\n",
    "    | protrusion   | [3]          |\n",
    "    | ...          | ...          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c6ba5",
   "metadata": {},
   "source": [
    "- Example: Query \"disc herniation spasm\"\n",
    "    1. Look up \"disc\" in the inverted index -> [1, 2, 3]\n",
    "    2. Look up \"herniation\" in the inverted index -> [2]\n",
    "    3. Look up \"spasm\" in the inverted index -> []\n",
    "    3. Intersect the document ID lists -> [2]\n",
    "    4. Result: Document 2 contains both terms \"disc\" and \"herniation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82193e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo of scoring when querying\n",
    "\n",
    "# 1. index 3 first documents into index\n",
    "for idx, row in text_data.head(3).iterrows():\n",
    "    doc = {\n",
    "        \"patient_id\": row['Patient ID'],\n",
    "        \"clinician_notes\": row[\"Clinician's Notes\"]\n",
    "    }\n",
    "    es.index(index=TEXT_INDEX, id=row['Patient ID'], body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea6487fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results for query 'disc herniation':\n",
      "- Patient ID: 2, Score: 1.4093384\n",
      "- Patient ID: 3, Score: 0.13481398\n",
      "- Patient ID: 1, Score: 0.10955827\n"
     ]
    }
   ],
   "source": [
    "# 2. perform a search query\n",
    "query_term = \"disc herniation\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"clinician_notes\": query_term\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "search_result = es.search(index=TEXT_INDEX, body=query_body)\n",
    "print(f\"Search Results for query '{query_term}':\")\n",
    "for hit in search_result['hits']['hits']:\n",
    "    print(f\"- Patient ID: {hit['_source']['patient_id']}, Score: {hit['_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1b4fe",
   "metadata": {},
   "source": [
    "- ES also provide an API to observe the frequency of a token in an indexed document, and number of documents in the whole index containing that token. This information is used to calculate the relevance score of a document for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "590df7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Vector for token 'disc':\n",
      "{'doc_freq': 3,\n",
      " 'term_freq': 1,\n",
      " 'tokens': [{'end_offset': 31, 'position': 4, 'start_offset': 27}],\n",
      " 'ttf': 3}\n"
     ]
    }
   ],
   "source": [
    "# demo termvector\n",
    "token = \"disc\"\n",
    "# token = \"annulus\"\n",
    "\n",
    "termvector = es.termvectors(\n",
    "    index=TEXT_INDEX,\n",
    "    id=str(text_data.loc[0, 'Patient ID']),\n",
    "    fields=[\"clinician_notes\"],\n",
    "    term_statistics=True\n",
    ")\n",
    "\n",
    "terms = termvector['term_vectors']['clinician_notes']['terms']\n",
    "if token in terms:\n",
    "    print(f\"Term Vector for token '{token}':\")\n",
    "    pprint(terms[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979675c",
   "metadata": {},
   "source": [
    "## 2. BKD Tree for Numeric/Spatial Data\n",
    "- BKD (block KD) trees keep numeric or spatial values in balanced blocks with bounding boxes, making range queries fast.\n",
    "- The demo below builds a tiny BKD tree over (x, y) coordinates and runs a rectangular range search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7a4a006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y  id\n",
       "0  0.374540  0.950714   0\n",
       "1  0.731994  0.598658   1\n",
       "2  0.156019  0.155995   2\n",
       "3  0.058084  0.866176   3\n",
       "4  0.601115  0.708073   4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy 2D points with ids\n",
    "rng = np.random.RandomState(42)\n",
    "points = rng.rand(20, 2)\n",
    "points_with_id = [(float(x), float(y), i) for i, (x, y) in enumerate(points)]\n",
    "pd.DataFrame(points_with_id, columns=['x', 'y', 'id']).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e20db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal BKD tree implementation (axis with largest spread is split each level)\n",
    "class BKDTree:\n",
    "    def __init__(self, points, leaf_size=4):\n",
    "        self.leaf_size = leaf_size\n",
    "        pts = np.array(points, dtype=float)\n",
    "        self.root = self._build(pts)\n",
    "\n",
    "    def _build(self, pts):\n",
    "        bbox_min = pts[:, :2].min(axis=0)\n",
    "        bbox_max = pts[:, :2].max(axis=0)\n",
    "        if len(pts) <= self.leaf_size:\n",
    "            return {'leaf': True, 'points': pts, 'bbox': (bbox_min, bbox_max)}\n",
    "\n",
    "        spreads = bbox_max - bbox_min\n",
    "        axis = int(np.argmax(spreads))\n",
    "        order = pts[:, axis].argsort()\n",
    "        pts = pts[order]\n",
    "        mid = len(pts) // 2\n",
    "\n",
    "        left = self._build(pts[:mid])\n",
    "        right = self._build(pts[mid:])\n",
    "        return {\n",
    "            'leaf': False,\n",
    "            'axis': axis,\n",
    "            'split_value': pts[mid, axis],\n",
    "            'bbox': (bbox_min, bbox_max),\n",
    "            'left': left,\n",
    "            'right': right\n",
    "        }\n",
    "\n",
    "    def range_query(self, query_min, query_max):\n",
    "        query_min = np.array(query_min)\n",
    "        query_max = np.array(query_max)\n",
    "        return self._range_query(self.root, query_min, query_max)\n",
    "\n",
    "    def _range_query(self, node, qmin, qmax):\n",
    "        bbox_min, bbox_max = node['bbox']\n",
    "        if np.any(bbox_max < qmin) or np.any(bbox_min > qmax):\n",
    "            return []\n",
    "\n",
    "        if node['leaf']:\n",
    "            pts = node['points']\n",
    "            mask = np.all((pts[:, :2] >= qmin) & (pts[:, :2] <= qmax), axis=1)\n",
    "            return [tuple(row) for row in pts[mask]]\n",
    "\n",
    "        return self._range_query(node['left'], qmin, qmax) + \\\n",
    "               self._range_query(node['right'], qmin, qmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b3ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query bbox x:[0.20, 0.80] y:[0.20, 0.60]\n",
      "Found 5 points in range:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.292145</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.524756</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431945</td>\n",
       "      <td>0.291229</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684233</td>\n",
       "      <td>0.440152</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y    id\n",
       "0  0.292145  0.366362  11.0\n",
       "1  0.304242  0.524756   8.0\n",
       "2  0.431945  0.291229   9.0\n",
       "3  0.684233  0.440152  19.0\n",
       "4  0.731994  0.598658   1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the tree and run a rectangular search\n",
    "tree = BKDTree(points_with_id, leaf_size=4)\n",
    "query_min = np.array([0.2, 0.2])\n",
    "query_max = np.array([0.8, 0.6])\n",
    "matches = tree.range_query(query_min, query_max)\n",
    "\n",
    "print(f'Query bbox x:[{query_min[0]:.2f}, {query_max[0]:.2f}] y:[{query_min[1]:.2f}, {query_max[1]:.2f}]')\n",
    "print(f'Found {len(matches)} points in range:')\n",
    "pd.DataFrame(matches, columns=['x', 'y', 'id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e32e7",
   "metadata": {},
   "source": [
    "## 3. Doc values\n",
    "- We'll index DICOM metadata, then show that range queries work for numeric fields, fail for text, and also fail if doc_values is disabled on a numeric field.\n",
    "- The helper `get_metadata` pulls many tags; we pick a handful to keep the mapping simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "740cd35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 8 sample DICOM files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_date</th>\n",
       "      <th>series_description</th>\n",
       "      <th>slice_thickness</th>\n",
       "      <th>spacing_between_slices</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOCALIZER_0_0001_001.ima</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>LOCALIZER_0_0001_001.ima_LOCALIZER_0_0001_001.ima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOCALIZER_0_0001_002.ima</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>LOCALIZER_0_0001_002.ima_LOCALIZER_0_0001_002.ima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOCALIZER_0_0001_003.ima</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>LOCALIZER_0_0001_003.ima_LOCALIZER_0_0001_003.ima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOCALIZER_0_0001_004.ima</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>LOCALIZER_0_0001_004.ima_LOCALIZER_0_0001_004.ima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOCALIZER_0_0001_005.ima</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>LOCALIZER_0_0001_005.ima_LOCALIZER_0_0001_005.ima</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 patient_id study_date series_description  slice_thickness  \\\n",
       "0  LOCALIZER_0_0001_001.ima       None               None              8.0   \n",
       "1  LOCALIZER_0_0001_002.ima       None               None              8.0   \n",
       "2  LOCALIZER_0_0001_003.ima       None               None              8.0   \n",
       "3  LOCALIZER_0_0001_004.ima       None               None              8.0   \n",
       "4  LOCALIZER_0_0001_005.ima       None               None              8.0   \n",
       "\n",
       "   spacing_between_slices  rows  columns  \\\n",
       "0                    12.0   512      512   \n",
       "1                    12.0   512      512   \n",
       "2                    12.0   512      512   \n",
       "3                    32.0   512      512   \n",
       "4                    32.0   512      512   \n",
       "\n",
       "                                              doc_id  \n",
       "0  LOCALIZER_0_0001_001.ima_LOCALIZER_0_0001_001.ima  \n",
       "1  LOCALIZER_0_0001_002.ima_LOCALIZER_0_0001_002.ima  \n",
       "2  LOCALIZER_0_0001_003.ima_LOCALIZER_0_0001_003.ima  \n",
       "3  LOCALIZER_0_0001_004.ima_LOCALIZER_0_0001_004.ima  \n",
       "4  LOCALIZER_0_0001_005.ima_LOCALIZER_0_0001_005.ima  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect some DICOM files\n",
    "LIMIT = 8\n",
    "from itertools import islice\n",
    "\n",
    "def iter_dicom_paths(root, limit=LIMIT):\n",
    "    for dirpath, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".ima\", \".dcm\")):\n",
    "                yield os.path.join(dirpath, f)\n",
    "        # no explicit break to allow nested dirs; limit handled by islice\n",
    "\n",
    "sample_paths = list(islice(iter_dicom_paths(IMAGE_DATA_DIR), 8))\n",
    "print(f'Load {len(sample_paths)} sample DICOM files')\n",
    "\n",
    "docs = []\n",
    "for path in sample_paths:\n",
    "    dicom = load_dicom(path)\n",
    "    metadata = get_metadata(dicom)\n",
    "    doc = {\n",
    "        'patient_id': metadata.get('PatientID') or os.path.basename(path),\n",
    "        'study_date': metadata.get('StudyDate'),\n",
    "        'series_description': metadata.get('SeriesDescription'),\n",
    "        'slice_thickness': float(metadata.get('SliceThickness', 0) or 0),\n",
    "        'spacing_between_slices': float(metadata.get('SpacingBetweenSlices', 0) or 0),\n",
    "        'rows': int(metadata.get('Rows', 0) or 0),\n",
    "        'columns': int(metadata.get('Columns', 0) or 0),\n",
    "    }\n",
    "    doc['doc_id'] = f\"{doc['patient_id']}_{os.path.basename(path)}\"\n",
    "    docs.append(doc)\n",
    "\n",
    "pd.DataFrame(docs).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ea18772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index dicom_metadata_docvalues_demo\n"
     ]
    }
   ],
   "source": [
    "# create an index with mapping; duplicate one numeric field with doc_values disabled\n",
    "DOC_INDEX = 'dicom_metadata_docvalues_demo'\n",
    "\n",
    "if es.indices.exists(index=DOC_INDEX):\n",
    "    es.indices.delete(index=DOC_INDEX)\n",
    "    print(f'Deleted existing index: {DOC_INDEX}')\n",
    "\n",
    "mapping = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'doc_id': {'type': 'keyword'},\n",
    "            'patient_id': {'type': 'keyword'},\n",
    "            'study_date': {'type': 'date', 'format': 'yyyyMMdd'},\n",
    "            'series_description': {'type': 'text'},\n",
    "            'slice_thickness': {'type': 'double'},\n",
    "            'spacing_between_slices': {'type': 'double'},\n",
    "            'rows': {'type': 'integer'},\n",
    "            'rows_no_docvals': {'type': 'integer', 'doc_values': False}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index=DOC_INDEX, body=mapping)\n",
    "print(f'Created index {DOC_INDEX}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cf15463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 8 documents into dicom_metadata_docvalues_demo\n"
     ]
    }
   ],
   "source": [
    "# index multiple documents; copy rows into a doc_values-disabled field\n",
    "actions = []\n",
    "for doc in docs:\n",
    "    src = dict(doc)\n",
    "    src['rows_no_docvals'] = src['rows']\n",
    "    actions.append({\n",
    "        '_index': DOC_INDEX,\n",
    "        '_id': src['doc_id'],\n",
    "        '_source': src\n",
    "    })\n",
    "helpers.bulk(es, actions)\n",
    "print(f'Indexed {len(actions)} documents into', DOC_INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "739c7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort on numeric slice_thickness -> hits: 8\n"
     ]
    }
   ],
   "source": [
    "# sort on numeric field works\n",
    "response = es.search(index=DOC_INDEX, sort=[{\n",
    "    'slice_thickness': 'asc'\n",
    "}])\n",
    "print('Sort on numeric slice_thickness -> hits:', response['hits']['total']['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac745fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort on text series_description -> error: BadRequestError(400, 'search_phase_execution_exception', 'Fielddata is disabled on [series_description] in [dicom_metadata_docvalues_demo]. Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [series_description] in order to load field data by uninverting the inverted index. Note that this can use significant memory.', Fielddata is disabled on [series_description] in [dicom_metadata_docvalues_demo]. Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [series_description] in order to load field data by uninverting the inverted index. Note that this can use significant memory.)\n"
     ]
    }
   ],
   "source": [
    "# sort on text field fails\n",
    "try:\n",
    "    reponse = es.search(index=DOC_INDEX, sort=[{\n",
    "        'series_description': 'asc'\n",
    "    }])\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print('Sort on text series_description -> error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fb322eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort on rows_no_docvals (doc_values: false) -> error: BadRequestError(400, 'search_phase_execution_exception', \"Can't load fielddata on [rows_no_docvals] because fielddata is unsupported on fields of type [integer]. Use doc values instead.\", Can't load fielddata on [rows_no_docvals] because fielddata is unsupported on fields of type [integer]. Use doc values instead.)\n"
     ]
    }
   ],
   "source": [
    "# sort on numeric field with doc_values disabled fails\n",
    "try:\n",
    "    es.search(index=DOC_INDEX, sort=[{\n",
    "        'rows_no_docvals': 'asc'\n",
    "    }])\n",
    "    print('Sort on rows_no_docvals (doc_values: false) -> success')\n",
    "except Exception as e:\n",
    "    print('Sort on rows_no_docvals (doc_values: false) -> error:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbms-assignment (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
