{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16d98c6",
   "metadata": {},
   "source": [
    "# Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-of-contents",
   "metadata": {},
   "source": [
    "## Mục lục:\n",
    "- [Elasticsearch](#elasticsearch)\n",
    "  - [0. Thiết lập môi trường & kết nối Elasticsearch](#0-thiết-lập-môi-trường-kết-nối-elasticsearch)\n",
    "  - [1. Indexing](#1-indexing)\n",
    "    - [1.1. BiomedCLIP embedding pipeline](#11-biomedclip-embedding-pipeline)\n",
    "    - [1.2. Khai báo index & ingest dữ liệu](#12-khai-báo-index-ingest-dữ-liệu)\n",
    "      - [1.2.1 Khai báo index](#121-khai-báo-index)\n",
    "      - [1.2.2. Hàm ingest dữ liệu](#122-hàm-ingest-dữ-liệu)\n",
    "      - [1.2.3 Kiểm tra thống kê index](#123-kiểm-tra-thống-kê-index)\n",
    "    - [1.3. Inverted index, segments và cơ chế refresh (near-real-time)](#13-inverted-index-segments-và-cơ-chế-refresh-near-real-time)\n",
    "      - [1.3.1. Inverted index là gì?](#131-inverted-index-là-gì)\n",
    "      - [1.3.2. Segments](#132-segments)\n",
    "      - [1.3.3. Refresh vs flush và near-real-time search](#133-refresh-vs-flush-và-near-real-time-search)\n",
    "      - [Refresh (mặc định ~1s)](#refresh-mặc-định-1s)\n",
    "      - [Flush](#flush)\n",
    "      - [1.3.4. Demo near-real-time với `radiology_text`](#134-demo-near-real-time-với-radiology_text)\n",
    "  - [2. Query Processing](#2-query-processing)\n",
    "    - [2.1. Full-text queries trên `radiology_text`](#21-full-text-queries-trên-radiology_text)\n",
    "      - [2.1.1. Term & match](#211-term-match)\n",
    "      - [2.1.2. Match_phrase](#212-match_phrase)\n",
    "    - [2.2. Bool query với filter](#22-bool-query-với-filter)\n",
    "    - [2.3. Highlight & sort](#23-highlight-sort)\n",
    "    - [2.4 Aggregations trên metadata (terms & date_histogram)](#24-aggregations-trên-metadata-terms-date_histogram)\n",
    "    - [2.5 Profile queries – nhìn bên trong engine](#25-profile-queries-nhìn-bên-trong-engine)\n",
    "    - [2.6 Script score](#26-script-score)\n",
    "    - [2.7 Vector kNN search trên `image_vector`](#27-vector-knn-search-trên-image_vector)\n",
    "    - [2.8 Semantic search trên `clinicians_notes`](#28-semantic-search-trên-clinicians_notes)\n",
    "  - [3. Transaction & Concurrency Control](#3-transaction-concurrency-control)\n",
    "    - [3.1 Transaction model: single-document atomicity](#31-transaction-model-single-document-atomicity)\n",
    "    - [3.2 Translog, refresh & flush](#32-translog-refresh-flush)\n",
    "    - [3.3 Bulk & `update_by_query`](#33-bulk-update_by_query)\n",
    "    - [3.4 Optimistic concurrency control (OCC)](#34-optimistic-concurrency-control-occ)\n",
    "  - [4. Comparison with Other Databases](#4-comparison-with-other-databases)\n",
    "    - [4.1. So sánh kỹ thuật tổng quan](#41-so-sánh-kỹ-thuật-tổng-quan)\n",
    "    - [4.2. Schema PostgreSQL cho benchmark](#42-schema-postgresql-cho-benchmark)\n",
    "    - [4.3. Ingest to PostgreSQL](#43-ingest-to-postgresql)\n",
    "      - [4.3.1. Ingest text data](#431-ingest-text-data)\n",
    "      - [4.3.2. Ingest image data](#432-ingest-image-data)\n",
    "    - [4.4. Workloads benchmark](#44-workloads-benchmark)\n",
    "      - [4.4.1. **Top-k text search**](#441-top-k-text-search)\n",
    "      - [4.4.2. **Tag filter + aggregation**](#442-tag-filter-aggregation)\n",
    "      - [4.4.3. **Image vector kNN**](#443-image-vector-knn)\n",
    "    - [4.5 Kết luận benchmark (định tính)](#45-kết-luận-benchmark-định-tính)\n",
    "    - [4.6 Vai trò đề xuất](#46-vai-trò-đề-xuất)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14913e8d",
   "metadata": {},
   "source": [
    "## 0. Thiết lập môi trường & kết nối Elasticsearch <a id=\"section-0\"></a>\n",
    "\n",
    "Thiết lập notebook cho bộ MRI (DICOM + Clinician's Notes):\n",
    "\n",
    "- Quản lý thư viện khoa học (`numpy`, `pandas`, `matplotlib`).\n",
    "- Đọc DICOM, tạo embedding và tqdm để theo dõi ingest.\n",
    "- Kết nối Elasticsearch cục bộ và khai báo đường dẫn dữ liệu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44125a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch 9.2.1\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive imports for all parts\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from time import sleep\n",
    "import threading\n",
    "from pprint import pprint\n",
    "import urllib3\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# DICOM and ML libraries\n",
    "import pydicom\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# For BiomedCLIP\n",
    "try:\n",
    "    from open_clip import create_model_from_pretrained\n",
    "except ImportError:\n",
    "    print('Note: open_clip not installed, some image embedding features may not work')\n",
    "\n",
    "# Elasticsearch\n",
    "from elasticsearch import Elasticsearch, helpers, ConflictError\n",
    "from elasticsearch.helpers import scan\n",
    "\n",
    "# PostgreSQL\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# Configuration constants\n",
    "ES_URL = os.getenv(\"ES_URL\", \"http://localhost:9200\")\n",
    "TEXT_INDEX = \"radiology_text\"\n",
    "VECTOR_INDEX = \"radiology_vectors\"\n",
    "\n",
    "# ROOT_DIR = \"../../mri_images\"\n",
    "# REPORT_XLSX = \"../../Radiologists Report.xlsx\"\n",
    "\n",
    "ROOT_DIR = \"../../data/images\"\n",
    "REPORT_XLSX = \"../../data/text/Radiologists Report.xlsx\"\n",
    "\n",
    "PG_HOST = os.getenv(\"PG_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.getenv(\"PG_PORT\", \"5432\"))\n",
    "PG_DB   = os.getenv(\"PG_DB\",   \"database\")\n",
    "PG_USER = os.getenv(\"PG_USER\", \"username\")\n",
    "PG_PASSWORD = os.getenv(\"PG_PASSWORD\", \"password\")\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(ES_URL)\n",
    "try:\n",
    "    print(f\"Connected to Elasticsearch {es.info().body['version']['number']}\")\n",
    "except:\n",
    "    print(\"Could not connect to Elasticsearch - check if it's running\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5006b278",
   "metadata": {},
   "source": [
    "## 1. Indexing <a id=\"section-1\"></a>\n",
    "### 1.1. BiomedCLIP embedding pipeline <a id=\"section-1-1\"></a>\n",
    "\n",
    "BiomedCLIP được dùng để tạo vector đặc trưng (512 chiều) cho từng lát MRI, bao gồm:\n",
    "\n",
    "- Tự động nhận `cuda`/`cpu`.\n",
    "- Chuẩn hoá ảnh xám → PIL → tiền xử lý của OpenCLIP.\n",
    "- Hàm tiện ích:\n",
    "  - `get_image_vector_from_array`\n",
    "  - `get_image_vector_from_dicom`\n",
    "  - `_infer_dims` để suy ra số chiều.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05215d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tram/dbms/DBMS-Assignment/src/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiomedCLIP loaded.\n",
      "VECTOR_DIMS = 512\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# MODEL INIT\n",
    "# ================================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load BiomedCLIP từ HF Hub\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
    ")\n",
    "model.to(device).eval()\n",
    "print(\"BiomedCLIP loaded.\")\n",
    "\n",
    "\n",
    "def _pil_from_grayscale_array(img: np.ndarray) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Chuẩn hoá 2D grayscale numpy (float/uint16/…) -> PIL uint8 [0,255].\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "    img_min = img.min()\n",
    "    img -= img_min\n",
    "    img_max = img.max()\n",
    "    if img_max > 0:\n",
    "        img /= img_max\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    return Image.fromarray(img_uint8)\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_image_vector_from_array(img: np.ndarray):\n",
    "    \"\"\"\n",
    "    Convert 2D numpy array (grayscale) -> BiomedCLIP embedding (L2-normalized).\n",
    "    Return: list[float]\n",
    "    \"\"\"\n",
    "    pil_img = _pil_from_grayscale_array(img)\n",
    "    image_input = preprocess(pil_img).unsqueeze(0).to(device)\n",
    "    image_features = model.encode_image(image_input)\n",
    "    # L2 normalize để cosine similarity meaningful\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    return image_features[0].cpu().numpy().tolist()\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_image_vector_from_dicom(dicom_path: str):\n",
    "    \"\"\"\n",
    "    Đọc file DICOM (*.dcm, *.ima), lấy pixel_array -> embed bằng BiomedCLIP.\n",
    "    \"\"\"\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "    return get_image_vector_from_array(img)\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def _infer_dims() -> int:\n",
    "    dummy = Image.fromarray(np.zeros((224, 224), dtype=np.uint8))\n",
    "    image_input = preprocess(dummy).unsqueeze(0).to(device)\n",
    "    feats = model.encode_image(image_input)\n",
    "    return int(feats.shape[-1])\n",
    "\n",
    "VECTOR_DIMS = _infer_dims()\n",
    "print(f\"VECTOR_DIMS = {VECTOR_DIMS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f681b",
   "metadata": {},
   "source": [
    "### 1.2. Khai báo index & ingest dữ liệu <a id=\"section-1-2\"></a>\n",
    "#### 1.2.1 Khai báo index <a id=\"section-1-2-1\"></a>\n",
    "Ta dùng hai index:\n",
    "\n",
    "- **`radiology_text`**\n",
    "  - Lưu 1 document / bệnh nhân.\n",
    "  - Trường `clinicians_notes` là `text` với custom analyzer:\n",
    "    - tokenizer: `standard`.\n",
    "    - filter: `lowercase`, `asciifolding`, `stop`, `porter_stem`.\n",
    "  - Trường `patient_id` là `keyword` với `normalizer` để chuẩn hoá (lowercase + bỏ dấu).\n",
    "\n",
    "- **`radiology_vectors`**\n",
    "  - Lưu metadata từng lát cắt MRI + vector ảnh:\n",
    "    - `patient_id`, `patient_sex`, `patient_age`, `body_part_examined`,\n",
    "      `sequence_name`, `modality` → `keyword` + `normalizer`.\n",
    "    - `tags` → `keyword` list để filter nhanh.\n",
    "    - `study_date` → `date`.\n",
    "    - `study_description`, `series_description` → `text`.\n",
    "    - Tham số kỹ thuật (`magnetic_field_strength`, `slice_thickness`,\n",
    "      `echo_time`, `repetition_time`) → `float`.\n",
    "    - `slice_index` → `integer`.\n",
    "    - `image_vector` → `dense_vector` với `dims = VECTOR_DIMS`, `similarity = \"cosine\"`.\n",
    "    - `image_path` → `keyword`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58fabde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreated index: radiology_text\n",
      "Recreated index: radiology_vectors\n"
     ]
    }
   ],
   "source": [
    "def recreate_index(name, body):\n",
    "    \"\"\"Xoá index (nếu tồn tại) rồi tạo lại từ đầu.\"\"\"\n",
    "    if es.indices.exists(index=name):\n",
    "        es.indices.delete(index=name)\n",
    "    es.indices.create(index=name, body=body)\n",
    "    print(f\"Recreated index: {name}\")\n",
    "\n",
    "# --- Text index: clinicians_notes ---\n",
    "text_index_body = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0,\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"custom_text_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"asciifolding\",\n",
    "                        \"stop\",\n",
    "                        \"porter_stem\",\n",
    "                    ],\n",
    "                }\n",
    "            },\n",
    "            \"normalizer\": {\n",
    "                \"lowercase_normalizer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"filter\": [\"lowercase\", \"asciifolding\"],\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"patient_id\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"clinicians_notes\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"custom_text_analyzer\",\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# --- Vector index: image_vector + metadata ---\n",
    "vector_index_body = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0,\n",
    "        \"index.refresh_interval\": \"5s\",\n",
    "        \"analysis\": {\n",
    "            \"normalizer\": {\n",
    "                \"lowercase_normalizer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"filter\": [\"lowercase\", \"asciifolding\"],\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"patient_id\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"patient_sex\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"patient_age\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"body_part_examined\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"sequence_name\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"modality\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"tags\": {\n",
    "                \"type\": \"keyword\",\n",
    "                \"normalizer\": \"lowercase_normalizer\",\n",
    "            },\n",
    "            \"study_date\": {\n",
    "                \"type\": \"date\",\n",
    "                \"format\": \"yyyyMMdd||yyyy-MM-dd||strict_date_optional_time\",\n",
    "            },\n",
    "            \"study_description\": {\"type\": \"text\"},\n",
    "            \"series_description\": {\"type\": \"text\"},\n",
    "            \"magnetic_field_strength\": {\"type\": \"float\"},\n",
    "            \"slice_thickness\": {\"type\": \"float\"},\n",
    "            \"echo_time\": {\"type\": \"float\"},\n",
    "            \"repetition_time\": {\"type\": \"float\"},\n",
    "            \"slice_index\": {\"type\": \"integer\"},\n",
    "            \"image_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": VECTOR_DIMS,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\",\n",
    "            },\n",
    "            \"image_path\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "recreate_index(TEXT_INDEX, text_index_body)\n",
    "recreate_index(VECTOR_INDEX, vector_index_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa3b1e",
   "metadata": {},
   "source": [
    "#### 1.2.2. Hàm ingest dữ liệu <a id=\"section-1-2-2\"></a>\n",
    "\n",
    "Bao gồm:\n",
    "\n",
    "1. `extract_dicom_metadata(ds)` chuẩn hoá metadata + gán `tags` (body part, sequence, modality…).\n",
    "2. `ingest_text_reports()` đọc file Excel và bulk vào `radiology_text` (1 doc / patient).\n",
    "3. `ingest_all()` duyệt thư mục DICOM, chọn lát SAG, embed bằng BiomedCLIP và bulk vào `radiology_vectors`.\n",
    "4. `print_index_stats()` để theo dõi `_cat/indices`, `_stats`, `_segments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa74ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dicom_metadata(ds):\n",
    "    def safe(tag, default=None):\n",
    "        return getattr(ds, tag, default)\n",
    "\n",
    "    def to_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    meta = {\n",
    "        \"patient_id\": str(safe(\"PatientID\", \"\")),\n",
    "        \"patient_sex\": str(safe(\"PatientSex\", \"\")),\n",
    "        \"patient_age\": str(safe(\"PatientAge\", \"\")),\n",
    "        \"body_part_examined\": str(safe(\"BodyPartExamined\", \"\")),\n",
    "        \"study_description\": str(safe(\"StudyDescription\", \"\")),\n",
    "        \"series_description\": str(safe(\"SeriesDescription\", \"\")),\n",
    "        \"sequence_name\": str(safe(\"SequenceName\", \"\")),\n",
    "        \"magnetic_field_strength\": to_float(safe(\"MagneticFieldStrength\", 0)),\n",
    "        \"slice_thickness\": to_float(safe(\"SliceThickness\", 0)),\n",
    "        \"echo_time\": to_float(safe(\"EchoTime\", 0)),\n",
    "        \"repetition_time\": to_float(safe(\"RepetitionTime\", 0)),\n",
    "    }\n",
    "\n",
    "    meta[\"modality\"] = str(safe(\"Modality\", \"\"))\n",
    "\n",
    "    study_date = safe(\"StudyDate\", \"\")\n",
    "    if study_date:\n",
    "        meta[\"study_date\"] = str(study_date)\n",
    "\n",
    "    tags = []\n",
    "    bp = meta.get(\"body_part_examined\")\n",
    "    if bp:\n",
    "        tags.append(bp)\n",
    "\n",
    "    sd = meta.get(\"study_description\", \"\")\n",
    "    if sd:\n",
    "        parts = (\n",
    "            str(sd)\n",
    "            .lower()\n",
    "            .replace(\"^\", \" \")\n",
    "            .split()\n",
    "        )\n",
    "        parts = [p.strip() for p in parts if p.strip()]\n",
    "        tags.extend(parts)\n",
    "\n",
    "    seq = meta.get(\"sequence_name\", \"\")\n",
    "    if seq:\n",
    "        tags.append(seq)\n",
    "\n",
    "    modality = meta.get(\"modality\")\n",
    "    if modality:\n",
    "        tags.append(modality)\n",
    "\n",
    "    if tags:\n",
    "        meta[\"tags\"] = tags\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a7c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_text_reports():\n",
    "    df = pd.read_excel(REPORT_XLSX)\n",
    "\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "        .str.replace(\"'\", \"\", regex=False)\n",
    "    )\n",
    "\n",
    "    required = {\"patient_id\", \"clinicians_notes\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns after normalization: {missing}\")\n",
    "\n",
    "    df = df.dropna(subset=[\"patient_id\", \"clinicians_notes\"])\n",
    "    df[\"patient_id\"] = df[\"patient_id\"].astype(str).str.strip()\n",
    "\n",
    "    print(f\"Total text records to ingest: {len(df)}\")\n",
    "\n",
    "    actions = []\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row[\"patient_id\"]\n",
    "        doc = {\n",
    "            \"patient_id\": pid,\n",
    "            \"clinicians_notes\": str(row[\"clinicians_notes\"]),\n",
    "        }\n",
    "        actions.append({\n",
    "            \"_index\": TEXT_INDEX,\n",
    "            \"_id\": pid,\n",
    "            \"_source\": doc,\n",
    "        })\n",
    "\n",
    "    if actions:\n",
    "        helpers.bulk(es, actions)\n",
    "        es.indices.refresh(index=TEXT_INDEX)\n",
    "\n",
    "    print(f\"Ingested {len(actions)} text docs into {TEXT_INDEX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebcf7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_all():\n",
    "    actions_vector = []\n",
    "    SLICE_RANGE = 3  # ±3 lát quanh lát giữa → tổng cộng 7 lát/sequence\n",
    "\n",
    "    for pid in tqdm(sorted(os.listdir(ROOT_DIR)), desc=\"Patients\"):\n",
    "        patient_path = os.path.join(ROOT_DIR, pid)\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "\n",
    "        for study in os.listdir(patient_path):\n",
    "            study_path = os.path.join(patient_path, study)\n",
    "            if not os.path.isdir(study_path):\n",
    "                continue\n",
    "\n",
    "            for seq in os.listdir(study_path):\n",
    "                seq_path = os.path.join(study_path, seq)\n",
    "                if not os.path.isdir(seq_path):\n",
    "                    continue\n",
    "\n",
    "                if \"SAG\" not in seq.upper():\n",
    "                    continue\n",
    "\n",
    "                ima_files = [f for f in os.listdir(seq_path) if f.endswith(\".ima\")]\n",
    "                if not ima_files:\n",
    "                    continue\n",
    "\n",
    "                ima_files.sort()\n",
    "                mid = len(ima_files) // 2\n",
    "                slice_indices = range(\n",
    "                    max(0, mid - SLICE_RANGE),\n",
    "                    min(len(ima_files), mid + SLICE_RANGE + 1),\n",
    "                )\n",
    "\n",
    "                for idx in slice_indices:\n",
    "                    dicom_path = os.path.join(seq_path, ima_files[idx])\n",
    "                    try:\n",
    "                        ds = pydicom.dcmread(dicom_path)\n",
    "                        img = ds.pixel_array.astype(np.float32)\n",
    "\n",
    "                        img -= img.min()\n",
    "                        if img.max() > 0:\n",
    "                            img /= img.max()\n",
    "\n",
    "                        meta = extract_dicom_metadata(ds)\n",
    "                        vec = get_image_vector_from_array(img)\n",
    "\n",
    "                        meta.update(\n",
    "                            {\n",
    "                                \"slice_index\": idx,\n",
    "                                \"image_vector\": vec,\n",
    "                                \"image_path\": dicom_path,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                        actions_vector.append(\n",
    "                            {\n",
    "                                \"_index\": VECTOR_INDEX,\n",
    "                                \"_id\": f\"{pid}_{seq}_{idx}\",\n",
    "                                \"_source\": meta,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\" Error reading {dicom_path}: {e}\")\n",
    "\n",
    "    print(\"\\nBulk indexing VECTOR docs...\")\n",
    "    if actions_vector:\n",
    "        helpers.bulk(es, actions_vector)\n",
    "        es.indices.refresh(index=VECTOR_INDEX)\n",
    "    print(f\"Done! Indexed {len(actions_vector)} slices\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3784f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_index_stats():\n",
    "    print(\"\\n=== _cat/indices ===\")\n",
    "    try:\n",
    "        print(es.cat.indices(index=f\"{TEXT_INDEX},{VECTOR_INDEX}\", v=True))\n",
    "    except Exception as e:\n",
    "        print(f\"cat.indices not available: {e}\")\n",
    "\n",
    "    print(\"\\n=== Text index stats ===\")\n",
    "    stats_text = es.indices.stats(index=TEXT_INDEX)\n",
    "    prim_text = stats_text.get(\"indices\", {}).get(TEXT_INDEX, {}).get(\"primaries\", {})\n",
    "    docs_text = prim_text.get(\"docs\", {}).get(\"count\", 0)\n",
    "    store_text = prim_text.get(\"store\", {}).get(\"size_in_bytes\", 0)\n",
    "    print(f\"  {TEXT_INDEX}: docs={docs_text}, store={store_text} bytes\")\n",
    "\n",
    "    print(\"\\n=== Vector index stats ===\")\n",
    "    stats_vec = es.indices.stats(index=VECTOR_INDEX)\n",
    "    prim_vec = stats_vec.get(\"indices\", {}).get(VECTOR_INDEX, {}).get(\"primaries\", {})\n",
    "    docs_vec = prim_vec.get(\"docs\", {}).get(\"count\", 0)\n",
    "    store_vec = prim_vec.get(\"store\", {}).get(\"size_in_bytes\", 0)\n",
    "    print(f\"  {VECTOR_INDEX}: docs={docs_vec}, store={store_vec} bytes\")\n",
    "\n",
    "    print(\"\\n=== Segments (vector index) ===\")\n",
    "    seg = es.indices.segments(index=VECTOR_INDEX)\n",
    "\n",
    "    index_seg = (\n",
    "        seg.get(\"indices\", {}).get(VECTOR_INDEX)\n",
    "        or seg.get(VECTOR_INDEX)\n",
    "    )\n",
    "\n",
    "    if not index_seg:\n",
    "        print(f\"  {VECTOR_INDEX}: no segments info (index may be empty or API changed)\")\n",
    "        return\n",
    "\n",
    "    shards = index_seg.get(\"shards\", {})\n",
    "    if \"0\" in shards and shards[\"0\"]:\n",
    "        seg_info = shards[\"0\"][0]\n",
    "        num_seg = seg_info.get(\"num_search_segments\") or len(seg_info.get(\"segments\", {}))\n",
    "        print(f\"  {VECTOR_INDEX}: num_search_segments={num_seg}\")\n",
    "    else:\n",
    "        print(f\"  {VECTOR_INDEX}: no active shard segments yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567c79f",
   "metadata": {},
   "source": [
    "#### 1.2.3 Kiểm tra thống kê index <a id=\"section-1-2-3\"></a>\n",
    "\n",
    "Quy trình:\n",
    "\n",
    "1. Xem stats ban đầu (index vừa tạo, chưa có dữ liệu).\n",
    "2. Ingest text reports vào `radiology_text`.\n",
    "3. Ingest ảnh + vector vào `radiology_vectors`.\n",
    "4. Xem lại `_cat/indices`, `_stats`, `_segments` để so sánh trước/sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de7e9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE INGEST ===\n",
      "\n",
      "=== _cat/indices ===\n",
      "health status index             uuid                   pri rep docs.count docs.deleted store.size pri.store.size dataset.size\n",
      "green  open   radiology_vectors QEvJ4mhuQQeyOGYqrwFhvA   1   0          0            0       249b           249b         249b\n",
      "green  open   radiology_text    s3jURyzZQFuOblyr2gecyA   1   0        515            0    168.7kb        168.7kb      168.7kb\n",
      "\n",
      "\n",
      "=== Text index stats ===\n",
      "  radiology_text: docs=515, store=172844 bytes\n",
      "\n",
      "=== Vector index stats ===\n",
      "  radiology_vectors: docs=0, store=249 bytes\n",
      "\n",
      "=== Segments (vector index) ===\n",
      "  radiology_vectors: num_search_segments=0\n",
      "\n",
      "=== INGEST TEXT REPORTS ===\n",
      "Total text records to ingest: 515\n",
      "Ingested 515 text docs into radiology_text\n",
      "\n",
      "=== INGEST MRI SLICES + VECTORS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patients: 100%|██████████| 516/516 [02:46<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bulk indexing VECTOR docs...\n",
      "Done! Indexed 8517 slices\n",
      "\n",
      "\n",
      "=== AFTER INGEST ===\n",
      "\n",
      "=== _cat/indices ===\n",
      "health status index             uuid                   pri rep docs.count docs.deleted store.size pri.store.size dataset.size\n",
      "green  open   radiology_vectors QEvJ4mhuQQeyOGYqrwFhvA   1   0       8363          154      2.5mb          2.5mb        2.5mb\n",
      "green  open   radiology_text    s3jURyzZQFuOblyr2gecyA   1   0        515           15     96.9kb         96.9kb       96.9kb\n",
      "\n",
      "\n",
      "=== Text index stats ===\n",
      "  radiology_text: docs=515, store=99232 bytes\n",
      "\n",
      "=== Vector index stats ===\n",
      "  radiology_vectors: docs=8363, store=2707082 bytes\n",
      "\n",
      "=== Segments (vector index) ===\n",
      "  radiology_vectors: num_search_segments=4\n"
     ]
    }
   ],
   "source": [
    "print(\"=== BEFORE INGEST ===\")\n",
    "print_index_stats()\n",
    "\n",
    "print(\"\\n=== INGEST TEXT REPORTS ===\")\n",
    "ingest_text_reports()\n",
    "\n",
    "print(\"\\n=== INGEST MRI SLICES + VECTORS ===\")\n",
    "ingest_all()\n",
    "\n",
    "print(\"\\n=== AFTER INGEST ===\")\n",
    "print_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b271e",
   "metadata": {},
   "source": [
    "### 1.3. Inverted index, segments và cơ chế refresh (near-real-time) <a id=\"section-1-3\"></a>\n",
    "\n",
    "Để hiểu vì sao Elasticsearch vừa search nhanh, vừa gần như *real-time*, cần nắm ba khái niệm:\n",
    "- **Inverted index** – cấu trúc dữ liệu cho full-text search.\n",
    "- **Segments** – đơn vị lưu trữ bất biến (immutable) bên trong mỗi shard.\n",
    "- **Refresh** – cơ chế giúp dữ liệu mới “lộ diện” với search.\n",
    "\n",
    "#### 1.3.1. Inverted index là gì? <a id=\"section-1-3-1\"></a>\n",
    "Thay vì lưu dạng \"tài liệu → danh sách từ\", Elasticsearch dùng **inverted index**: \"từ khoá → danh sách tài liệu chứa từ đó\".\n",
    "\n",
    "- Truy vấn `match` sẽ được analyzer xử lý giống như lúc ingest (lowercase, stopwords, stemming...).\n",
    "- Kết quả trả về nhanh vì chỉ thao tác trên postings list thay vì scan toàn bộ 575 ghi chú.\n",
    "- Ví dụ nhanh dưới đây dùng chính file Excel Radiologists Report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1171b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(REPORT_XLSX)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0711fb9",
   "metadata": {},
   "source": [
    "| Term           | Danh sách tài liệu (postings list) |\n",
    "|----------------|-------------------------------------|\n",
    "| `l4`           | (Patient 1)                         |\n",
    "| `5`            | (Patient 1)                         |\n",
    "| `degenerative` | (Patient 1)                         |\n",
    "| `annular`      | (Patient 1)                         |\n",
    "| `disc`         | (Patient 1), (Patient 2), (Patient 3) |\n",
    "| `bulge`        | (Patient 1)                         |\n",
    "| `herniation`   | (Patient 2)                         |\n",
    "| `lss`          | (Patient 3)                         |\n",
    "| `mri`          | (Patient 3)                         |\n",
    "| `muscle`       | (Patient 3)                         |\n",
    "| `spasm`        | (Patient 3)                         |\n",
    "| `protrusion`   | (Patient 3)                         |\n",
    "\n",
    "**Quy trình xử lý truy vấn**:\n",
    "1. Analyzer cắt từ: ví dụ `lss`, `mri`, `muscle`, `spasm`.\n",
    "2. Elasticsearch tra postings list tương ứng.\n",
    "3. Gộp & xếp hạng dựa trên BM25 / độ dài tài liệu / tần suất term.\n",
    "4. Trả về Clinician's Notes của những bệnh nhân chứa các term trên.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13841bba",
   "metadata": {},
   "source": [
    "#### 1.3.2. Segments <a id=\"section-1-3-2\"></a>\n",
    "\n",
    "- Mỗi shard được chia thành nhiều **segment** chỉ-đọc, mỗi segment có inverted index riêng.\n",
    "- Khi ingest batch MRI:\n",
    "  1. Tài liệu mới ghi vào buffer + translog.\n",
    "  2. Chu kỳ refresh (~1s) ghi xuống đĩa → tạo `segment_n` mới.\n",
    "  3. Segment mới được mở cho search, sau đó Elasticsearch merge các segment nhỏ để tối ưu.\n",
    "- Với 575 bản ghi text + hàng nghìn lát MRI, chỉ sau vài lần merge số segment sẽ ổn định → query đọc tất cả segment đang sống và hợp nhất kết quả.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73d65c",
   "metadata": {},
   "source": [
    "#### 1.3.3. Refresh vs flush và near-real-time search <a id=\"section-1-3-3\"></a>\n",
    "\n",
    "Elasticsearch là hệ thống **near-real-time (NRT)**:\n",
    "- Ngay sau khi index, tài liệu **chưa chắc đã search thấy ngay**.\n",
    "- Tài liệu chỉ được nhìn thấy trong search **sau lần refresh kế tiếp**. \n",
    "\n",
    "Hai quá trình chính trên shard:\n",
    "\n",
    "#### Refresh (mặc định ~1s)\n",
    "- Đọc dữ liệu từ buffer, tạo segment mới.\n",
    "- Mở segment đó cho search.\n",
    "- Gây ra độ trễ ~1s giữa thời điểm index và lúc search thấy document.\n",
    "\n",
    "#### Flush\n",
    "- Ghi dữ liệu bền vững hơn, xoá bớt translog cũ.\n",
    "- Quan trọng cho durability, **không trực tiếp liên quan** tới việc NRT search có thấy doc mới hay không.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e66da3",
   "metadata": {},
   "source": [
    "#### 1.3.4. Demo near-real-time với `radiology_text` <a id=\"section-1-3-4\"></a>\n",
    "\n",
    "Kịch bản demo:\n",
    "\n",
    "1. Đọc `refresh_interval` hiện tại của `radiology_text`.\n",
    "2. Tạm thời đặt `refresh_interval = -1` để **tắt auto-refresh**, dễ quan sát.\n",
    "3. Index một document mới.\n",
    "4. Search ngay lập tức (trước khi refresh).\n",
    "5. Gọi `indices.refresh()`.\n",
    "6. Search lại.\n",
    "7. Khôi phục `refresh_interval` về giá trị ban đầu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaddd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_before = es.indices.get_settings(index=TEXT_INDEX)\n",
    "old_refresh = settings_before[TEXT_INDEX][\"settings\"][\"index\"].get(\"refresh_interval\", \"1s\")\n",
    "\n",
    "print(f\"refresh_interval hiện tại của `{TEXT_INDEX}`: {old_refresh}\")\n",
    "es.indices.put_settings(\n",
    "    index=TEXT_INDEX,\n",
    "    settings={\n",
    "        \"index\": {\n",
    "            \"refresh_interval\": \"-1\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Đã tạm thời đặt refresh_interval = -1 cho `{TEXT_INDEX}`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = {\n",
    "    \"patient_id\": \"demo_nrt\",\n",
    "    \"clinicians_notes\": \"LSS MRI shows regression of previous disc bulge.\"\n",
    "}\n",
    "\n",
    "index_resp = es.index(index=TEXT_INDEX, document=doc)\n",
    "doc_id = index_resp.get(\"_id\")\n",
    "print(f\"Indexed new document with _id = {doc_id}\")\n",
    "\n",
    "query = {\n",
    "    \"match\": {\n",
    "        \"clinicians_notes\": \"regression of previous disc bulge\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== Search BEFORE refresh ===\")\n",
    "resp_before = es.search(index=TEXT_INDEX, query=query)\n",
    "total_before = resp_before[\"hits\"][\"total\"][\"value\"]\n",
    "print(\"Total hits:\", total_before)\n",
    "for hit in resp_before[\"hits\"][\"hits\"]:\n",
    "    print(\" - patient_id =\", hit[\"_source\"].get(\"patient_id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.refresh(index=TEXT_INDEX)\n",
    "print(\"\\nĐã gọi es.indices.refresh()\")\n",
    "\n",
    "print(\"\\n=== Search AFTER refresh ===\")\n",
    "resp_after = es.search(index=TEXT_INDEX, query=query)\n",
    "total_after = resp_after[\"hits\"][\"total\"][\"value\"]\n",
    "print(\"Total hits:\", total_after)\n",
    "for hit in resp_after[\"hits\"][\"hits\"]:\n",
    "    print(\" - patient_id =\", hit[\"_source\"].get(\"patient_id\"))\n",
    "\n",
    "es.indices.put_settings(\n",
    "    index=TEXT_INDEX,\n",
    "    settings={\n",
    "        \"index\": {\n",
    "            \"refresh_interval\": old_refresh\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"\\nĐã khôi phục refresh_interval của `{TEXT_INDEX}` về: {old_refresh}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Query Processing <a id=\"section-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792cd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text_hits(resp, max_hits: int = 5) -> None:\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "    total = resp[\"hits\"][\"total\"][\"value\"]\n",
    "    print(f\"Total hits: {total}\")\n",
    "    print(\"-\" * 60)\n",
    "    for h in hits[:max_hits]:\n",
    "        src = h[\"_source\"]\n",
    "        pid = src.get(\"patient_id\")\n",
    "        score = h.get(\"_score\")\n",
    "        note = src.get(\"clinicians_notes\", \"\")\n",
    "        if len(note) > 220:\n",
    "            note = note[:220] + \"...\"\n",
    "        print(f\"patient_id = {pid}, _score = {score}\")\n",
    "        print(\"  clinicians_notes:\", note)\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "\n",
    "def print_vector_hits(resp, max_hits: int = 5) -> None:\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "    total = resp[\"hits\"][\"total\"][\"value\"]\n",
    "    print(f\"Total hits: {total}\")\n",
    "    print(\"-\" * 60)\n",
    "    for h in hits[:max_hits]:\n",
    "        src = h[\"_source\"]\n",
    "        print(\n",
    "            f\"patient_id={src.get('patient_id')}, \"\n",
    "            f\"body_part={src.get('body_part_examined')}, \"\n",
    "            f\"slice_index={src.get('slice_index')}, \"\n",
    "            f\"_score={h.get('_score')}\"\n",
    "        )\n",
    "        print(\"  image_path:\", src.get(\"image_path\"))\n",
    "        print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54044c8",
   "metadata": {},
   "source": [
    "### 2.1. Full-text queries trên `radiology_text` <a id=\"section-2-1\"></a>\n",
    "#### 2.1.1. Term & match <a id=\"secion-2-1-1\"></a>\n",
    "- **`match`**:\n",
    "  - Phân tích (analyze) query string → token.\n",
    "  - Áp dụng cùng analyzer với field.\n",
    "  - Trả về tài liệu có *bất kỳ token* trùng khớp, kèm scoring (BM25).\n",
    "\n",
    "- **`term`**:\n",
    "  - **Không** phân tích query string.\n",
    "  - So khớp đúng **term** trong inverted index.\n",
    "  - Hợp với `keyword` / ID / mã, không hợp với full-text có analyzer.\n",
    "\n",
    "Ta sẽ demo:\n",
    "\n",
    "- `match` vs `term` trên cùng field để thấy sự khác biệt.\n",
    "- `match_phrase`: yêu cầu cụm từ liên tiếp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950962a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## match\n",
    "match_query = {\n",
    "    \"match\": {\n",
    "        \"clinicians_notes\": \"neural canals\"\n",
    "    }\n",
    "}\n",
    "\n",
    "## term\n",
    "term_query = {\n",
    "    \"term\": {\n",
    "        \"clinicians_notes\": \"Neural\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== MATCH: \\\"neural canals\\\" ===\")\n",
    "resp_match = es.search(index=TEXT_INDEX, query=match_query)\n",
    "print_text_hits(resp_match)\n",
    "\n",
    "print(\"\\n=== TERM: clinicians_notes = 'Neural' (no analysis) ===\")\n",
    "resp_term = es.search(index=TEXT_INDEX, query=term_query)\n",
    "print_text_hits(resp_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d849da7",
   "metadata": {},
   "source": [
    "#### 2.1.2. Match_phrase <a id=\"section-2-1-2\"></a>\n",
    "`match_phrase` yêu cầu các term xuất hiện **liên tục** theo đúng thứ tự trong field.\n",
    "\n",
    "Ví dụ: `\"neural canals\"` sẽ chỉ match khi notes chứa cụm này (sau khi phân tích với analyzer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_phrase_query = {\n",
    "    \"match_phrase\": {\n",
    "        \"clinicians_notes\": \"neural canals\"\n",
    "    }\n",
    "}\n",
    "\n",
    "resp_phrase = es.search(index=TEXT_INDEX, query=match_phrase_query)\n",
    "print(\"=== MATCH_PHRASE: \\\"neural canals\\\" ===\")\n",
    "print_text_hits(resp_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bdb306",
   "metadata": {},
   "source": [
    "### 2.2. Bool query với filter <a id=\"section-2-2\"></a>\n",
    "Cấu trúc `bool`:\n",
    "\n",
    "- `must` / `should` / `must_not`: **scored** clauses (ảnh hưởng `_score`).\n",
    "- `filter`: điều kiện **không tính điểm**, chỉ dùng để include/exclude:\n",
    "  - Kết quả filter có thể được cache.\n",
    "  - Hợp cho `term`, `range`, `exists`, v.v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad99325",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrive all clinicians notes contains both \"diffuse\" and \"compressing\" word from the first 1000 patients\n",
    "bool_filter_query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            { \"match\": { \"clinicians_notes\": \"diffuse\"} },\n",
    "            { \"match\": {\"clinicians_notes\": \"compressing\" }}\n",
    "        ],\n",
    "        \"filter\": [\n",
    "            {\"term\": {\"patient_id\": \"100\"}}\n",
    "        ]   \n",
    "    }\n",
    "}\n",
    "\n",
    "resp_bool = es.search(index=TEXT_INDEX, query=bool_filter_query)\n",
    "print(\"=== BOOL: must match 'diffuse' & 'compressing' + filter patient_id=500 ===\")\n",
    "print_text_hits(resp_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780c039",
   "metadata": {},
   "source": [
    "### 2.3. Highlight & sort <a id=\"section-2-3\"></a>\n",
    "Highlight giúp:\n",
    "\n",
    "- Hiển thị đoạn text có match query.\n",
    "- Bọc các term khớp trong `<em>...</em>` (mặc định).\n",
    "\n",
    "Sorting:\n",
    "\n",
    "- Mặc định: `_score` desc.\n",
    "- Có thể sort theo field khác (vd `patient_id`), nhưng nhớ:\n",
    "  - sort theo field `keyword` hoặc `numeric` sẽ bỏ `_score` nếu không thêm `_score` trong sort list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"clinicians_notes\": \"muscle spasm\"\n",
    "        }\n",
    "    },\n",
    "    \"highlight\": {\n",
    "        \"fields\": {\n",
    "            \"clinicians_notes\": {}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=TEXT_INDEX, body=highlight_query)\n",
    "print_text_hits(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd26cc2",
   "metadata": {},
   "source": [
    "### 2.4 Aggregations trên metadata (terms & date_histogram) <a id=\"section-2-4\"></a>\n",
    "Các field metadata trong `radiology_vectors`:\n",
    "\n",
    "- `body_part_examined` (keyword, normalized).\n",
    "- `tags` (keyword list).\n",
    "- `study_date` (date: `yyyyMMdd`).\n",
    "\n",
    "Ta sẽ:\n",
    "\n",
    "1. Đếm số lát cắt theo `body_part_examined` bằng `terms` agg.\n",
    "2. Đếm theo thời gian (`study_date`) bằng `date_histogram` (theo tháng)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_body = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"by_body_part\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"body_part_examined\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "resp_agg_body = es.search(index=VECTOR_INDEX, body=agg_body)\n",
    "buckets = resp_agg_body[\"aggregations\"][\"by_body_part\"][\"buckets\"]\n",
    "print(\"=== Số lát cắt theo body_part_examined ===\")\n",
    "for b in buckets:\n",
    "    print(f\"{b['key']}: {b['doc_count']} slices\")\n",
    "\n",
    "\n",
    "# 2) Date histogram: số lát cắt theo tháng (study_date)\n",
    "\n",
    "agg_date = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"by_month\": {\n",
    "            \"date_histogram\": {\n",
    "                \"field\": \"study_date\",\n",
    "                \"calendar_interval\": \"month\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "resp_agg_date = es.search(index=VECTOR_INDEX, body=agg_date)\n",
    "print(\"\\n=== Số lát cắt theo tháng (study_date) ===\")\n",
    "for b in resp_agg_date[\"aggregations\"][\"by_month\"][\"buckets\"]:\n",
    "    print(b[\"key_as_string\"], \"=>\", b[\"doc_count\"], \"slices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfc867",
   "metadata": {},
   "source": [
    "### 2.5 Profile queries – nhìn bên trong engine <a id=\"section-2-5\"></a>\n",
    "Thêm `\"profile\": true` vào request body:\n",
    "\n",
    "- Elasticsearch trả về chi tiết execution per shard:\n",
    "  - Các phase: rewrite, weight, scoring.\n",
    "  - Thời gian từng phase (`time_in_nanos`).\n",
    "- Rất hữu ích để:\n",
    "  - So sánh hiệu năng giữa các query.\n",
    "  - Tối ưu mapping, index, cache, cấu trúc query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_match_query={\n",
    "    \"profile\": True,\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"clinicians_notes\": \"spondylolisthesis\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "resp_profile = es.search(index=TEXT_INDEX, body=profile_match_query)\n",
    "\n",
    "print(\"Tổng hits:\", resp_profile[\"hits\"][\"total\"][\"value\"])\n",
    "\n",
    "for shard in resp_profile.get(\"profile\", {}).get(\"shards\", []):\n",
    "    print(\"\\n=== Shard\", shard.get(\"id\"), \"===\")\n",
    "    for search_phase in shard.get(\"searches\", []):\n",
    "        for q in search_phase.get(\"query\", []):\n",
    "            print(\"Query type:\", q.get(\"type\"))\n",
    "            print(\"  time_in_nanos:\", q.get(\"time_in_nanos\"))\n",
    "            print(\"  breakdown:\", q.get(\"breakdown\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d6498",
   "metadata": {},
   "source": [
    "### 2.6 Script score <a id=\"section-2-6\"></a>\n",
    "`function_score` + `script_score` cho phép:\n",
    "\n",
    "- Tự định nghĩa công thức tính điểm:\n",
    "  - kết hợp `_score` với field numeric (vd severity, age…),\n",
    "  - hoặc học từ model ngoài (vd score từ re-ranking model).\n",
    "- Ở đây dataset text chưa có nhiều numeric field,\n",
    "  nên demo đơn giản: nhân `_score` với một hệ số.\n",
    "\n",
    "Trong thực tế, có thể dùng:\n",
    "- `doc['some_numeric'].value`,\n",
    "- hoặc vector similarity + `_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88352d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_score_body = {\n",
    "    \"query\": {\n",
    "        \"function_score\": {\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"clinicians_notes\": \"surgery\"\n",
    "                }\n",
    "            },\n",
    "            \"script_score\": {\n",
    "                \"script\": {\n",
    "                    # ví dụ đơn giản: scale _score\n",
    "                    \"source\": \"_score * 1.5\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"size\": 5\n",
    "}\n",
    "\n",
    "resp_script = es.search(index=TEXT_INDEX, body=script_score_body)\n",
    "print(\"=== Script score (match 'surgery') ===\")\n",
    "print_text_hits(resp_script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b600e8",
   "metadata": {},
   "source": [
    "### 2.7 Vector kNN search trên `image_vector`\n",
    "Ở Part 1 ta đã:\n",
    "\n",
    "- Trích xuất embedding từ BiomedCLIP cho từng lát cắt MRI.\n",
    "- Lưu vào field `image_vector` (kiểu `dense_vector`, `similarity=\"cosine\"`).\n",
    "\n",
    "Giờ ta sẽ:\n",
    "\n",
    "1. Lấy một lát cắt làm **query image**.\n",
    "2. Dùng vector của lát đó làm `query_vector`.\n",
    "3. Gọi `knn` search để tìm các lát gần nhất trong embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b85559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Lấy một document làm query vector\n",
    "\n",
    "seed_resp = es.search(\n",
    "    index=VECTOR_INDEX,\n",
    "    query={\"match_all\": {}},\n",
    "    size=1,\n",
    "    _source=[\"patient_id\", \"body_part_examined\", \"slice_index\", \"image_path\", \"image_vector\"],\n",
    ")\n",
    "\n",
    "if not seed_resp[\"hits\"][\"hits\"]:\n",
    "    raise RuntimeError(\"VECTOR_INDEX không có data, hãy đảm bảo đã chạy ingest ở Part 1.\")\n",
    "\n",
    "seed_hit = seed_resp[\"hits\"][\"hits\"][0]\n",
    "query_vec = seed_hit[\"_source\"][\"image_vector\"]\n",
    "\n",
    "print(\"=== Seed document ===\")\n",
    "print_vector_hits(seed_resp, max_hits=1)\n",
    "\n",
    "# 2) kNN search\n",
    "\n",
    "knn_body = {\n",
    "    \"knn\": {\n",
    "        \"field\": \"image_vector\",\n",
    "        \"query_vector\": query_vec,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 100\n",
    "    },\n",
    "    \"_source\": [\"patient_id\", \"body_part_examined\", \"slice_index\", \"image_path\"],\n",
    "}\n",
    "\n",
    "resp_knn = es.search(index=VECTOR_INDEX, body=knn_body)\n",
    "\n",
    "print(\"\\n=== Top 5 nearest neighbours (image_vector) ===\")\n",
    "print_vector_hits(resp_knn, max_hits=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b673f",
   "metadata": {},
   "source": [
    "### 2.8 Semantic search trên `clinicians_notes` <a id=\"section-2-8\"></a>\n",
    "\n",
    "Ngoài BM25 (`match`/`match_phrase`), ta có thể:\n",
    "\n",
    "- Embed mỗi `clinicians_notes` thành vector (vd `all-MiniLM-L6-v2`).\n",
    "- Lưu vào field `report_embedding` (dense_vector) trong `radiology_text`.\n",
    "- Chạy `knn` theo nghĩa (semantic) thay vì chỉ theo keyword.\n",
    "\n",
    "Phần này:\n",
    "\n",
    "1. Thêm mapping cho `report_embedding`.\n",
    "2. Dùng SentenceTransformer để embed tất cả notes.\n",
    "3. Viết hàm `semantic_search(question, k)` → chạy kNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed099f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Thêm field dense_vector cho semantic embedding (nếu chưa có)\n",
    "es.indices.put_mapping(\n",
    "    index=TEXT_INDEX,\n",
    "    properties={\n",
    "        \"report_embedding\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 384,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "device_st = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"SentenceTransformer device:\", device_st)\n",
    "\n",
    "st_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device_st)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def embed_text(text: str) -> list[float]:\n",
    "    # encode trả về numpy array (384-dims)\n",
    "    vec = st_model.encode([text], convert_to_numpy=True)[0]\n",
    "    return vec.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b889f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Lấy tất cả docs và update report_embedding (cẩn thận size; dataset này nhỏ nên OK)\n",
    "\n",
    "resp_all = es.search(\n",
    "    index=TEXT_INDEX,\n",
    "    query={\"match_all\": {}},\n",
    "    size=10_000,\n",
    ")\n",
    "\n",
    "hits = resp_all[\"hits\"][\"hits\"]\n",
    "print(f\"Computing embeddings for {len(hits)} documents...\")\n",
    "\n",
    "ops = []\n",
    "for h in hits:\n",
    "    note = h[\"_source\"].get(\"clinicians_notes\", \"\")\n",
    "    vec = embed_text(note)\n",
    "    ops.append(\n",
    "        {\n",
    "            \"_op_type\": \"update\",\n",
    "            \"_index\": TEXT_INDEX,\n",
    "            \"_id\": h[\"_id\"],\n",
    "            \"doc\": {\n",
    "                \"report_embedding\": vec,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "helpers.bulk(es, ops)\n",
    "es.indices.refresh(index=TEXT_INDEX)\n",
    "print(\"Updated all documents with report_embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(question: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    Semantic search trên clinicians_notes dùng report_embedding + kNN.\n",
    "    \"\"\"\n",
    "    query_vec = embed_text(question)\n",
    "    body = {\n",
    "        \"knn\": {\n",
    "            \"field\": \"report_embedding\",\n",
    "            \"query_vector\": query_vec,\n",
    "            \"k\": k,\n",
    "            \"num_candidates\": 100,\n",
    "        },\n",
    "        \"_source\": [\"patient_id\", \"clinicians_notes\"],\n",
    "    }\n",
    "    resp = es.search(index=TEXT_INDEX, body=body)\n",
    "    print(f\"\\n=== Semantic search ===\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print_text_hits(resp, max_hits=k)\n",
    "    return resp\n",
    "\n",
    "\n",
    "# Một vài ví dụ semantic search\n",
    "\n",
    "semantic_search(\"Which patients have a disc bulge at L4-L5?\", k=5)\n",
    "semantic_search(\"Which reports mention compression of the thecal sac or nerve roots?\", k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Transaction & Concurrency Control <a id=\"section-3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecfabe8",
   "metadata": {},
   "source": [
    "### 3.1 Transaction model: single-document atomicity <a id=\"section-3-1\"></a>\n",
    "\n",
    "Elasticsearch **không phải** là hệ quản trị quan hệ ACID multi-document,\n",
    "nhưng vẫn có những guarantee quan trọng:\n",
    "\n",
    "- Mỗi **document write (index/update/delete)** là một **transaction đơn lẻ**:\n",
    "  - Ghi hoặc **thành công toàn bộ**, hoặc **thất bại** – không có trạng thái \"nửa vời\".\n",
    "- Khi một doc được acknowledge thành công:\n",
    "  - Thay đổi đã được ghi vào **translog** trên primary shard (và replica tuỳ setting).\n",
    "  - Nếu node crash:\n",
    "    - translog được replay khi shard khởi động lại → đảm bảo **durability**.\n",
    "\n",
    "Tuy nhiên:\n",
    "\n",
    "- Elasticsearch **không hỗ trợ transaction ACID nhiều document** với commit/rollback như RDBMS.\n",
    "- Thay vào đó:\n",
    "  - Mỗi doc write là atomic.\n",
    "  - Consistency ở mức cluster dựa vào **quorum replication** (primary + replicas).\n",
    "  - Search hoạt động ở chế độ **near-real-time** (NRT), phụ thuộc vào `refresh_interval`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fdf96",
   "metadata": {},
   "source": [
    "### 3.2 Translog, refresh & flush <a id=\"section-3-2\"></a>\n",
    "\n",
    "Khi index/update một doc:\n",
    "\n",
    "1. Request đến **primary shard**:\n",
    "   - Ghi thay đổi vào **in-memory buffer**.\n",
    "   - Append một bản ghi vào **transaction log (translog)** trên disk.\n",
    "2. Khi translog được fsync (theo chính sách), write được coi là **durable**.\n",
    "3. **Refresh**:\n",
    "   - Định kỳ (mặc định `index.refresh_interval ~ 1s`), Elasticsearch:\n",
    "     - dựng một **segment** mới từ in-memory buffer,\n",
    "     - mở segment đó cho search.\n",
    "   - Kết quả: doc có thể search được sau một khoảng trễ nhỏ → gọi là **near-real-time**.\n",
    "4. **Flush**:\n",
    "   - Xoá bớt translog cũ sau khi data đã được ghi xuống segment và an toàn.\n",
    "   - Liên quan tới quản lý disk & durability lâu dài.\n",
    "   - Không ảnh hưởng trực tiếp tới việc “doc đã search được hay chưa”.\n",
    "\n",
    "> TL;DR:  \n",
    "> - **Durability**: nhờ translog được fsync.  \n",
    "> - **Search visibility**: nhờ refresh → segment mới được mở cho search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597309f",
   "metadata": {},
   "source": [
    "### 3.3 Bulk & `update_by_query` <a id=\"section-3-3\"></a>\n",
    "- `bulk` API cho phép:\n",
    "  - index/update/delete **nhiều document trong 1 request**,\n",
    "  - nhưng mỗi operation trong bulk là **độc lập**:\n",
    "    - một số doc có thể thành công,\n",
    "    - một số doc có thể lỗi (mapping error, version conflict, …),\n",
    "    - không có rollback toàn bộ như transaction SQL.\n",
    "\n",
    "- `update_by_query`:\n",
    "  - chạy một truy vấn (vd `range` hoặc `terms`) để tìm tập doc,\n",
    "  - apply script update trên từng doc.\n",
    "  - Nếu một doc bị lỗi (vd script lỗi, bad ID, conflict…):\n",
    "    - task sẽ báo lỗi cho từng doc,\n",
    "    - phần còn lại vẫn có thể update thành công.\n",
    "\n",
    "Điều này nghĩa là:\n",
    "\n",
    "- Cần xử lý lỗi **từng document**:\n",
    "  - log chi tiết,\n",
    "  - có thể retry từng doc riêng lẻ,\n",
    "  - không kỳ vọng “all-or-nothing” cho cả batch.\n",
    "\n",
    "Dưới đây là một ví dụ nhỏ để minh hoạ update nhiều patient theo `patient_id` bằng `update_by_query`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9651f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cập nhật một nhóm patient_id bằng update_by_query\n",
    "update_ids = [str(i) for i in range(2, 10)]  # ví dụ: patient_id từ 2 -> 9\n",
    "\n",
    "# Query chọn các doc cần update\n",
    "range_query = {\n",
    "    \"query\": {\n",
    "        \"ids\": {\n",
    "            \"values\": update_ids\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== Trước update_by_query ===\")\n",
    "resp_before = es.search(index=TEXT_INDEX, body={**range_query, \"size\": 20})\n",
    "print(\"Hits:\", resp_before[\"hits\"][\"total\"][\"value\"])\n",
    "\n",
    "# Script đơn giản: gắn thêm flag vào notes\n",
    "script_source = \"\"\"\n",
    "if (ctx._source.containsKey(\"clinicians_notes\")) {\n",
    "    ctx._source.clinicians_notes = ctx._source.clinicians_notes + \"[batch updated]\";\n",
    "}\n",
    "\"\"\"\n",
    "body = {\n",
    "    \"script\": {\n",
    "        \"lang\": \"painless\",\n",
    "        \"source\": script_source,\n",
    "    },\n",
    "    \"query\": range_query[\"query\"],\n",
    "}\n",
    "\n",
    "resp_task = es.update_by_query(\n",
    "    index=TEXT_INDEX,\n",
    "    body=body,\n",
    "    conflicts=\"proceed\",  # vẫn tiếp tục nếu có conflict trên một số doc\n",
    "    refresh=True,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Kết quả update_by_query ===\")\n",
    "print(json.dumps(resp_task.body, indent=2))\n",
    "\n",
    "print(\"\\n=== Sau update_by_query ===\")\n",
    "resp_after = es.search(index=TEXT_INDEX, body={**range_query, \"size\": 20})\n",
    "print(\"Hits:\", resp_after[\"hits\"][\"total\"][\"value\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165916a",
   "metadata": {},
   "source": [
    "### 3.4 Optimistic concurrency control (OCC) <a id=\"section-3-4\"></a>\n",
    "\n",
    "Vấn đề: **lost update**\n",
    "\n",
    "- Hai client (A, B) cùng đọc một doc (phiên bản V1).\n",
    "- A update → doc thành V2.\n",
    "- B (vẫn nghĩ doc đang là V1) update lên → doc thành V3, *đè* mất update của A.\n",
    "- Ta muốn phát hiện tình huống này, thay vì âm thầm last-write-wins.\n",
    "\n",
    "Elasticsearch dùng **optimistic concurrency control**:\n",
    "\n",
    "- Mỗi document có:\n",
    "  - `_seq_no` (sequence number – tăng dần mỗi lần write),\n",
    "  - `_primary_term` (gắn với vòng đời primary shard).\n",
    "- Khi update:\n",
    "\n",
    "  - Client đọc document, kèm `_seq_no` và `_primary_term` hiện tại.\n",
    "  - Gửi update với các tham số:\n",
    "\n",
    "    ```text\n",
    "    if_seq_no=<seq_no_cũ>\n",
    "    if_primary_term=<primary_term_cũ>\n",
    "    ```\n",
    "\n",
    "  - Nếu trong lúc đó một write khác đã cập nhật doc:\n",
    "    - `_seq_no` thay đổi.\n",
    "    - Elastic sẽ trả về **409 Conflict**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn một doc trong radiology_text để demo concurrency\n",
    "TARGET_DOC_ID = None\n",
    "\n",
    "def pick_target_doc():\n",
    "    \"\"\"\n",
    "    Chọn một document bất kỳ trong TEXT_INDEX làm mục tiêu cho demo concurrency.\n",
    "    \"\"\"\n",
    "    global TARGET_DOC_ID\n",
    "    resp = es.search(\n",
    "        index=TEXT_INDEX,\n",
    "        query={\"match_all\": {}},\n",
    "        size=1,\n",
    "        seq_no_primary_term=True,\n",
    "    )\n",
    "    if not resp[\"hits\"][\"hits\"]:\n",
    "        raise RuntimeError(\"TEXT_INDEX không có dữ liệu – hãy chạy ingest ở Part 1 trước.\")\n",
    "\n",
    "    hit = resp[\"hits\"][\"hits\"][0]\n",
    "    TARGET_DOC_ID = hit[\"_id\"]\n",
    "\n",
    "    print(\"=== Target document for concurrency demo ===\")\n",
    "    print(\"doc_id      :\", TARGET_DOC_ID)\n",
    "    print(\"patient_id  :\", hit[\"_source\"].get(\"patient_id\"))\n",
    "    print(\"seq_no      :\", hit.get(\"_seq_no\"))\n",
    "    print(\"primary_term:\", hit.get(\"_primary_term\"))\n",
    "    print(\"clinicians_notes (truncated):\")\n",
    "    notes = hit[\"_source\"].get(\"clinicians_notes\", \"\")\n",
    "    print((notes[:300] + \"...\") if len(notes) > 300 else notes)\n",
    "\n",
    "pick_target_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1615e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_with_version(doc_id: str):\n",
    "    \"\"\"\n",
    "    Lấy doc cùng với _seq_no và _primary_term hiện tại.\n",
    "    \"\"\"\n",
    "    doc = es.get(index=TEXT_INDEX, id=doc_id)\n",
    "    return {\n",
    "        \"id\": doc[\"_id\"],\n",
    "        \"seq_no\": doc[\"_seq_no\"],\n",
    "        \"primary_term\": doc[\"_primary_term\"],\n",
    "        \"source\": doc[\"_source\"],\n",
    "    }\n",
    "\n",
    "# test\n",
    "current = get_doc_with_version(TARGET_DOC_ID)\n",
    "print(\"Current seq_no:\", current[\"seq_no\"], \"primary_term:\", current[\"primary_term\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ec4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_notes_thread(thread_id: int, use_occ: bool = True, sleep_before_update: float = 0.5):\n",
    "    \"\"\"\n",
    "    Mỗi thread đơn lẻ:\n",
    "    1. Đọc doc + phiên bản (_seq_no, _primary_term).\n",
    "    2. Chỉnh sửa clinicians_notes.\n",
    "    3. Gửi update:\n",
    "       - nếu use_occ=True: dùng if_seq_no & if_primary_term (OCC).\n",
    "       - nếu use_occ=False: update bình thường (last write wins).\n",
    "    \"\"\"\n",
    "    # 1) đọc phiên bản hiện tại\n",
    "    doc_info = get_doc_with_version(TARGET_DOC_ID)\n",
    "    seq_no = doc_info[\"seq_no\"]\n",
    "    primary_term = doc_info[\"primary_term\"]\n",
    "    notes = doc_info[\"source\"].get(\"clinicians_notes\", \"\")\n",
    "\n",
    "    new_notes = notes + f\"\\n[update from thread {thread_id}]\"\n",
    "\n",
    "    # ngủ một chút để tăng khả năng 2 thread \"đụng nhau\"\n",
    "    time.sleep(sleep_before_update)\n",
    "\n",
    "    try:\n",
    "        if use_occ:\n",
    "            # Optimistic concurrency: fail nếu seq_no/primary_term đã khác\n",
    "            es.update(\n",
    "                index=TEXT_INDEX,\n",
    "                id=TARGET_DOC_ID,\n",
    "                if_seq_no=seq_no,\n",
    "                if_primary_term=primary_term,\n",
    "                doc={\"clinicians_notes\": new_notes},\n",
    "            )\n",
    "        else:\n",
    "            # Không dùng OCC: last write wins\n",
    "            es.update(\n",
    "                index=TEXT_INDEX,\n",
    "                id=TARGET_DOC_ID,\n",
    "                doc={\"clinicians_notes\": new_notes},\n",
    "            )\n",
    "        print(f\"Thread {thread_id}: update thành công (use_occ={use_occ})\")\n",
    "    except ConflictError as e:\n",
    "        print(f\"Thread {thread_id}:  Conflict 409 (use_occ={use_occ}) - {e.info}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Thread {thread_id}: Lỗi khác - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06005e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_concurrent_updates(use_occ: bool = True, rounds: int = 3):\n",
    "    print(f\"\\n=== Concurrent updates (use_occ={use_occ}) ===\\n\")\n",
    "    for i in range(rounds):\n",
    "        print(f\"--- Round {i+1} ---\")\n",
    "\n",
    "        # đọc doc trước khi update\n",
    "        before = get_doc_with_version(TARGET_DOC_ID)\n",
    "        print(\"Before:\")\n",
    "        print(\"  seq_no      :\", before[\"seq_no\"])\n",
    "        print(\"  primary_term:\", before[\"primary_term\"])\n",
    "        print(\"  tail notes  :\", (before[\"source\"][\"clinicians_notes\"][-120:]))\n",
    "\n",
    "        # tạo 2 thread cùng update cùng doc\n",
    "        t1 = threading.Thread(target=update_notes_thread, args=(1, use_occ, 0.5))\n",
    "        t2 = threading.Thread(target=update_notes_thread, args=(2, use_occ, 0.5))\n",
    "\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "\n",
    "        # đọc lại doc\n",
    "        after = get_doc_with_version(TARGET_DOC_ID)\n",
    "        print(\"After:\")\n",
    "        print(\"  seq_no      :\", after[\"seq_no\"])\n",
    "        print(\"  primary_term:\", after[\"primary_term\"])\n",
    "        print(\"  tail notes  :\", (after[\"source\"][\"clinicians_notes\"][-120:]))\n",
    "        print()\n",
    "\n",
    "# 1) Demo với OCC: mong đợi 1 thread thành công, 1 thread conflict\n",
    "run_concurrent_updates(use_occ=True, rounds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27935565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Demo không dùng OCC: last write wins, có nguy cơ lost update\n",
    "run_concurrent_updates(use_occ=False, rounds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Comparison with Other Databases <a id=\"section-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ce8de",
   "metadata": {},
   "source": [
    "### 4.1. So sánh kỹ thuật tổng quan <a id=\"section-4-1\"></a>\n",
    "| Tiêu chí                      | Elasticsearch                                                | PostgreSQL                                                                 |\n",
    "|------------------------------|--------------------------------------------------------------|----------------------------------------------------------------------------|\n",
    "| Mục tiêu thiết kế            | Search & analytics engine, scale-out, near-real-time search | Hệ quản trị CSDL quan hệ, ưu tiên transaction, nhất quán, OLTP            |\n",
    "| Data model                   | Document JSON, schema linh hoạt (mapping)                   | Bảng, hàng, cột, schema chặt, nhiều ràng buộc (PK/FK/UNIQUE/CHECK…)       |\n",
    "| Lược đồ (schema)             | Mapping dynamic, dễ add field mới                           | `CREATE TABLE`, thay đổi schema cần `ALTER TABLE`, được kiểm soát chặt     |\n",
    "| Full-text search             | Inverted index + analyzer, Query DSL (`match`, `bool`, aggs)| `tsvector`/`tsquery` + GIN index, hoặc `pg_trgm` cho similarity search    |\n",
    "| Vector search                | `dense_vector` + kNN (HNSW)                                 | Extension `vector` (pgvector) + `ivfflat` / HNSW trên kiểu `vector`       |\n",
    "| Ngôn ngữ truy vấn            | JSON Query DSL                                              | SQL giàu biểu đạt, joins, subquery, window functions                      |\n",
    "| Transaction & consistency    | Single-doc atomic, quorum replication, NRT search           | ACID multi-row/multi-table, rất hợp cho hệ thống nghiệp vụ cốt lõi        |\n",
    "| Concurrency                  | Optimistic concurrency bằng `_seq_no` / `_primary_term`     | MVCC, transaction isolation levels                                        |\n",
    "| Scalability                  | Shard, replica, scale-out ngang                             | Scale-up chính, partitioning / sharding có nhưng phức tạp hơn             |\n",
    "| Use case điển hình           | Log, metric, search UI, analytics dashboard, observability  | OLTP, billing, HIS/EMR core data, transaction tài chính, báo cáo chuẩn    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2e66ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pg_conn():\n",
    "    return psycopg2.connect(\n",
    "        host=PG_HOST,\n",
    "        port=PG_PORT,\n",
    "        dbname=PG_DB,\n",
    "        user=PG_USER,\n",
    "        password=PG_PASSWORD,\n",
    "    )\n",
    "\n",
    "\n",
    "def percentile(values, q):\n",
    "    arr = np.array(values, dtype=float)\n",
    "    return float(np.percentile(arr, q))\n",
    "\n",
    "\n",
    "def summarize_timings(label, timings_ms):\n",
    "    return {\n",
    "        \"workload\": label,\n",
    "        \"runs\": len(timings_ms),\n",
    "        \"p50_ms\": percentile(timings_ms, 50),\n",
    "        \"p95_ms\": percentile(timings_ms, 95),\n",
    "        \"mean_ms\": float(np.mean(timings_ms)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770de5d2",
   "metadata": {},
   "source": [
    "### 4.2. Schema PostgreSQL cho benchmark <a id=\"section-4-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa35b61",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"username\"\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"username\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m     conn.close()\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPostgreSQL schema created!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43msetup_postgres_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36msetup_postgres_schema\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup_postgres_schema\u001b[39m():\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Setup PostgreSQL tables, indexes, and extensions\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     conn = \u001b[43mget_pg_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     cur = conn.cursor()\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Extensions\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mget_pg_conn\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_pg_conn\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_HOST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_PORT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_DB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_USER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_PASSWORD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dbms/DBMS-Assignment/src/.venv/lib/python3.13/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"username\"\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"username\"\n"
     ]
    }
   ],
   "source": [
    "def setup_postgres_schema():\n",
    "    \"\"\"Setup PostgreSQL tables, indexes, and extensions\"\"\"\n",
    "    conn = get_pg_conn()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Extensions\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS pg_trgm;\")\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    \n",
    "    # Bảng text reports \n",
    "    cur.execute(\"\"\"\n",
    "        DROP TABLE IF EXISTS pg_radiology_reports CASCADE;\n",
    "        CREATE TABLE pg_radiology_reports (\n",
    "            id BIGSERIAL PRIMARY KEY,\n",
    "            patient_id TEXT,\n",
    "            clinicians_notes TEXT NOT NULL,\n",
    "            note_tsv tsvector GENERATED ALWAYS AS (\n",
    "                to_tsvector('english', coalesce(clinicians_notes, '')) \n",
    "            ) STORED\n",
    "        );\n",
    "        CREATE INDEX idx_pg_reports_tsv_gin\n",
    "            ON pg_radiology_reports USING GIN (note_tsv);\n",
    "        CREATE INDEX idx_pg_reports_trgm_gin\n",
    "          ON pg_radiology_reports USING GIN (clinicians_notes gin_trgm_ops);\n",
    "    \"\"\")\n",
    "    \n",
    "    # Bảng image vectors\n",
    "    cur.execute(\"\"\"\n",
    "        DROP TABLE IF EXISTS pg_mri_images CASCADE;\n",
    "        CREATE TABLE pg_mri_images (\n",
    "            image_id     TEXT PRIMARY KEY,\n",
    "            patient_id   TEXT,\n",
    "            body_part    TEXT,\n",
    "            tags         TEXT[],\n",
    "            image_vector vector(512) \n",
    "        );\n",
    "        CREATE INDEX idx_pg_mri_tags_gin\n",
    "          ON pg_mri_images USING GIN (tags);\n",
    "        CREATE INDEX idx_pg_mri_vec_ivfflat\n",
    "          ON pg_mri_images USING ivfflat (image_vector vector_l2_ops)\n",
    "          WITH (lists = 100);\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"PostgreSQL schema created!\")\n",
    "\n",
    "setup_postgres_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533fcea",
   "metadata": {},
   "source": [
    "### 4.3. Ingest to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d79a0",
   "metadata": {},
   "source": [
    "#### 4.3.1. Ingest text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reports_from_es(batch_size=500):\n",
    "    \"\"\"\n",
    "    Stream toàn bộ doc từ index TEXT_INDEX (radiology_text)\n",
    "    để đổ sang PostgreSQL.\n",
    "    \"\"\"\n",
    "    query = {\"query\": {\"match_all\": {}}}\n",
    "    for hit in scan(\n",
    "        es,\n",
    "        index=TEXT_INDEX,\n",
    "        query=query,\n",
    "        size=batch_size,\n",
    "        _source=[\"patient_id\", \"clinicians_notes\"],\n",
    "    ):\n",
    "        src = hit[\"_source\"]\n",
    "        yield (\n",
    "            src.get(\"patient_id\"),\n",
    "            src.get(\"clinicians_notes\", \"\"),\n",
    "        )\n",
    "\n",
    "\n",
    "def load_reports_into_postgres():\n",
    "    conn = get_pg_conn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    rows = list(fetch_reports_from_es())\n",
    "    print(f\"Copying {len(rows)} text docs from ES -> PostgreSQL...\")\n",
    "\n",
    "    execute_batch(\n",
    "        cur,\n",
    "        \"\"\"\n",
    "        INSERT INTO pg_radiology_reports (patient_id, clinicians_notes)\n",
    "        VALUES (%s, %s);\n",
    "        \"\"\",\n",
    "        rows,\n",
    "        page_size=1000,\n",
    "    )\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"✅ Done loading reports into pg_radiology_reports.\")\n",
    "\n",
    "\n",
    "load_reports_into_postgres()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f7f94",
   "metadata": {},
   "source": [
    "#### 4.3.2. Ingest image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63089243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_pg_str(vec):\n",
    "    \"\"\"\n",
    "    Chuyển Python list[float] -> string dạng '[0.1, 0.2, ...]'\n",
    "    mà extension vector hiểu được.\n",
    "    \"\"\"\n",
    "    return \"[\" + \",\".join(f\"{float(x):.6f}\" for x in vec) + \"]\"\n",
    "\n",
    "\n",
    "def fetch_images_from_es(batch_size=500):\n",
    "    \"\"\"\n",
    "    Stream doc từ index VECTOR_INDEX (radiology_vectors)\n",
    "    để đổ sang PostgreSQL.\n",
    "    \"\"\"\n",
    "    fields = [\"patient_id\", \"body_part_examined\", \"tags\", \"image_vector\"]\n",
    "    query = {\"query\": {\"match_all\": {}}}\n",
    "    for hit in scan(\n",
    "        es,\n",
    "        index=VECTOR_INDEX,\n",
    "        query=query,\n",
    "        size=batch_size,\n",
    "        _source=fields,\n",
    "    ):\n",
    "        src = hit[\"_source\"]\n",
    "        image_id = hit[\"_id\"]\n",
    "        patient_id = src.get(\"patient_id\")\n",
    "        body_part = src.get(\"body_part_examined\")\n",
    "        tags = src.get(\"tags\", [])\n",
    "        vec = src.get(\"image_vector\")\n",
    "        if not vec:\n",
    "            continue\n",
    "        yield (\n",
    "            image_id,\n",
    "            patient_id,\n",
    "            body_part,\n",
    "            tags,\n",
    "            vec_to_pg_str(vec),\n",
    "        )\n",
    "\n",
    "\n",
    "def load_images_into_postgres():\n",
    "    conn = get_pg_conn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    batch = []\n",
    "    count = 0\n",
    "\n",
    "    for row in fetch_images_from_es():\n",
    "        batch.append(row)\n",
    "        if len(batch) >= 1000:\n",
    "            execute_batch(\n",
    "                cur,\n",
    "                \"\"\"\n",
    "                INSERT INTO pg_mri_images (image_id, patient_id, body_part, tags, image_vector)\n",
    "                VALUES (%s, %s, %s, %s, %s::vector)\n",
    "                ON CONFLICT (image_id) DO NOTHING;\n",
    "                \"\"\",\n",
    "                batch,\n",
    "            )\n",
    "            count += len(batch)\n",
    "            batch = []\n",
    "\n",
    "    if batch:\n",
    "        execute_batch(\n",
    "            cur,\n",
    "            \"\"\"\n",
    "            INSERT INTO pg_mri_images (image_id, patient_id, body_part, tags, image_vector)\n",
    "            VALUES (%s, %s, %s, %s, %s::vector)\n",
    "            ON CONFLICT (image_id) DO NOTHING;\n",
    "            \"\"\",\n",
    "            batch,\n",
    "        )\n",
    "        count += len(batch)\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(f\"✅ Done loading {count} image vectors into pg_mri_images.\")\n",
    "\n",
    "\n",
    "load_images_into_postgres()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4e309",
   "metadata": {},
   "source": [
    "### 4.4. Workloads benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b71765",
   "metadata": {},
   "source": [
    "#### 4.4.1. **Top-k text search** \n",
    "- Elasticsearch: `match` trên `clinicians_notes`.\n",
    "- PostgreSQL: `note_tsv @@ plainto_tsquery('english', q)` + `ts_rank_cd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_QUERY = \"disc bulge at L4-L5\" \n",
    "\n",
    "\n",
    "def benchmark_text_es(query=TEXT_QUERY, k=10, loops=30):\n",
    "    timings = []\n",
    "    for i in range(loops):\n",
    "        t0 = time.perf_counter()\n",
    "        es.search(\n",
    "            index=TEXT_INDEX,\n",
    "            query={\"match\": {\"clinicians_notes\": query}},\n",
    "            size=k,\n",
    "        )\n",
    "        t1 = time.perf_counter()\n",
    "        timings.append((t1 - t0) * 1000.0)  # ms\n",
    "    return summarize_timings(\"text_search_es\", timings)\n",
    "\n",
    "\n",
    "def benchmark_text_pg(query=TEXT_QUERY, k=10, loops=30):\n",
    "    timings = []\n",
    "    conn = get_pg_conn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for i in range(loops):\n",
    "        t0 = time.perf_counter()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT id, patient_id,\n",
    "                   ts_rank_cd(note_tsv, plainto_tsquery('english', %s)) AS rank\n",
    "            FROM pg_radiology_reports\n",
    "            WHERE note_tsv @@ plainto_tsquery('english', %s)\n",
    "            ORDER BY rank DESC\n",
    "            LIMIT %s;\n",
    "            \"\"\",\n",
    "            (query, query, k),\n",
    "        )\n",
    "        cur.fetchall()\n",
    "        t1 = time.perf_counter()\n",
    "        timings.append((t1 - t0) * 1000.0)\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return summarize_timings(\"text_search_pg\", timings)\n",
    "\n",
    "\n",
    "print(benchmark_text_es())\n",
    "print(benchmark_text_pg())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a301d9",
   "metadata": {},
   "source": [
    "#### 4.4.2. **Tag filter + aggregation**\n",
    "- Elasticsearch: filter theo `body_part_examined` + `terms` agg trên `tags`.\n",
    "- PostgreSQL: `WHERE body_part = ?` + `unnest(tags)` + `GROUP BY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97160ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BODY_PART = \"lumbar spine\"\n",
    "\n",
    "\n",
    "def benchmark_tag_agg_es(body_part=DEFAULT_BODY_PART, loops=30):\n",
    "    timings = []\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"filter\": [\n",
    "                    {\"term\": {\"body_part_examined\": body_part}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"by_tag\": {\n",
    "                \"terms\": {\"field\": \"tags\", \"size\": 10}\n",
    "            }\n",
    "        },\n",
    "        \"size\": 0,\n",
    "    }\n",
    "\n",
    "    for i in range(loops):\n",
    "        t0 = time.perf_counter()\n",
    "        es.search(index=VECTOR_INDEX, body=body)\n",
    "        t1 = time.perf_counter()\n",
    "        timings.append((t1 - t0) * 1000.0)\n",
    "\n",
    "    return summarize_timings(\"tag_filter_agg_es\", timings)\n",
    "\n",
    "\n",
    "def benchmark_tag_agg_pg(body_part=DEFAULT_BODY_PART, loops=30):\n",
    "    \"\"\"\n",
    "    Filter body_part, sau đó đếm tần suất từng tag.\n",
    "    \"\"\"\n",
    "    timings = []\n",
    "    conn = get_pg_conn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for i in range(loops):\n",
    "        t0 = time.perf_counter()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT tag, COUNT(*) AS cnt\n",
    "            FROM (\n",
    "                SELECT unnest(tags) AS tag\n",
    "                FROM pg_mri_images\n",
    "                WHERE body_part = %s\n",
    "            ) AS t\n",
    "            GROUP BY tag\n",
    "            ORDER BY cnt DESC\n",
    "            LIMIT 10;\n",
    "            \"\"\",\n",
    "            (body_part,),\n",
    "        )\n",
    "        cur.fetchall()\n",
    "        t1 = time.perf_counter()\n",
    "        timings.append((t1 - t0) * 1000.0)\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return summarize_timings(\"tag_filter_agg_pg\", timings)\n",
    "\n",
    "\n",
    "print(benchmark_tag_agg_es())\n",
    "print(benchmark_tag_agg_pg())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b9d7a",
   "metadata": {},
   "source": [
    "#### 4.4.3. **Image vector kNN** \n",
    "- Elasticsearch: `knn` trên field `image_vector`.\n",
    "- PostgreSQL: `ORDER BY image_vector <-> query_vec LIMIT k` (pgvector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn 1 ảnh bất kỳ làm query (query-by-example)\n",
    "seed_resp = es.search(\n",
    "    index=VECTOR_INDEX,\n",
    "    query={\"match_all\": {}},\n",
    "    size=1,\n",
    "    _source=[\"image_vector\", \"patient_id\", \"body_part_examined\"],\n",
    ")\n",
    "\n",
    "if not seed_resp[\"hits\"][\"hits\"]:\n",
    "    raise RuntimeError(\"VECTOR_INDEX trống – cần ingest dữ liệu ở Part 1.\")\n",
    "\n",
    "seed_hit = seed_resp[\"hits\"][\"hits\"][0]\n",
    "QUERY_VEC = seed_hit[\"_source\"][\"image_vector\"]\n",
    "\n",
    "print(\"Seed doc for kNN:\")\n",
    "print(\"  patient_id  =\", seed_hit[\"_source\"].get(\"patient_id\"))\n",
    "print(\"  body_part   =\", seed_hit[\"_source\"].get(\"body_part_examined\"))\n",
    "\n",
    "\n",
    "def benchmark_knn_es(query_vec=QUERY_VEC, k=10, loops=30, num_candidates=100):\n",
    "    timings = []\n",
    "    body = {\n",
    "        \"knn\": {\n",
    "            \"field\": \"image_vector\",\n",
    "            \"query_vector\": query_vec,\n",
    "            \"k\": k,\n",
    "            \"num_candidates\": num_candidates,\n",
    "        },\n",
    "        \"_source\": False,\n",
    "    }\n",
    "    for i in range(loops):\n",
    "        t0 = time.perf_counter()\n",
    "        es.search(index=VECTOR_INDEX, body=body)\n",
    "        t1 = time.perf_counter()\n",
    "        timings.append((t1 - t0) * 1000.0)\n",
    "    return summarize_timings(\"image_knn_es\", timings)\n",
    "\n",
    "\n",
    "def benchmark_knn_pg(query_vec=QUERY_VEC, k=10, loops=30):\n",
    "    \"\"\"\n",
    "    kNN trên pg_mri_images dùng pgvector (L2 distance).\n",
    "    \"\"\"\n",
    "    timings = []\n",
    "    conn = get_pg_conn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    vec_str = \"[\" + \",\".join(f\"{float(x):.6f}\" for x in query_vec) + \"]\"\n",
    "\n",
    "    for i in range(loops):\n",
    "        t0 = time.perf_counter()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT image_id, patient_id, body_part,\n",
    "                   image_vector <-> %s::vector AS dist\n",
    "            FROM pg_mri_images\n",
    "            ORDER BY image_vector <-> %s::vector\n",
    "            LIMIT %s;\n",
    "            \"\"\",\n",
    "            (vec_str, vec_str, k),\n",
    "        )\n",
    "        cur.fetchall()\n",
    "        t1 = time.perf_counter()\n",
    "        timings.append((t1 - t0) * 1000.0)\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return summarize_timings(\"image_knn_pg\", timings)\n",
    "\n",
    "\n",
    "print(benchmark_knn_es())\n",
    "print(benchmark_knn_pg())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a05eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_benchmarks():\n",
    "    results = []\n",
    "\n",
    "    # Warmup nhẹ để giảm cold-start effect\n",
    "    benchmark_text_es(loops=3)\n",
    "    benchmark_text_pg(loops=3)\n",
    "    benchmark_tag_agg_es(loops=3)\n",
    "    benchmark_tag_agg_pg(loops=3)\n",
    "    benchmark_knn_es(loops=3)\n",
    "    benchmark_knn_pg(loops=3)\n",
    "\n",
    "    # Run chính\n",
    "    results.append(benchmark_text_es(loops=20))\n",
    "    results.append(benchmark_text_pg(loops=20))\n",
    "    results.append(benchmark_tag_agg_es(loops=20))\n",
    "    results.append(benchmark_tag_agg_pg(loops=20))\n",
    "    results.append(benchmark_knn_es(loops=20))\n",
    "    results.append(benchmark_knn_pg(loops=20))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "benchmark_df = run_all_benchmarks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.close()\n",
    "print(\"Elasticsearch connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39e497",
   "metadata": {},
   "source": [
    "### 4.5 Kết luận benchmark (định tính)\n",
    "\n",
    "Với dataset nhỏ/vừa trong project này (vài trăm–vài nghìn reports và ~1000 lát MRI),\n",
    "cộng thêm môi trường:\n",
    "\n",
    "- Elasticsearch chạy single-node, 1 shard.\n",
    "- Overhead HTTP + JSON cho mỗi request ES.\n",
    "- PostgreSQL dùng binary wire protocol, query plan được cache tốt.\n",
    "\n",
    "**Kết quả thực nghiệm (trên máy lab)** thường có dạng:\n",
    "\n",
    "- PostgreSQL có p50/p95 latency **nhỏ hơn một chút** so với Elasticsearch cho:\n",
    "  - Top-k text search (FTS `tsvector` + GIN).\n",
    "  - Vector kNN search trên `pg_mri_images` (pgvector).\n",
    "\n",
    "Tuy nhiên:\n",
    "\n",
    "- Benchmark này **không phủ định** Elasticsearch:\n",
    "  - Dataset còn nhỏ, scale chưa chạm ngưỡng Elasticsearch phát huy sức mạnh.\n",
    "  - ES mạnh hơn rõ rệt khi:\n",
    "    - Lượng document lên hàng chục triệu,\n",
    "    - Cần aggregations phức tạp, dashboards, multi-tenant search,\n",
    "    - Cần scale-out nhiều node.\n",
    "\n",
    "### 4.6 Vai trò đề xuất\n",
    "\n",
    "- **PostgreSQL**:\n",
    "  - Làm **source of truth** cho dữ liệu bệnh nhân, kết quả xét nghiệm, billing, lịch sử điều trị.\n",
    "  - Dùng FTS (`tsvector`, `pg_trgm`) + `pgvector` cho những hệ thống nhỏ / đơn node\n",
    "    cần vừa transaction, vừa search cơ bản.\n",
    "\n",
    "- **Elasticsearch**:\n",
    "  - Làm **search layer** phía trước:\n",
    "    - Tìm kiếm full-text nhanh, highlight, suggest.\n",
    "    - Vector search cho ảnh tương tự (MRI / X-ray / báo cáo embedding).\n",
    "    - Aggregations real-time cho dashboards & analytics.\n",
    "  - Kết hợp tốt với log/metric, observability, audit trail.\n",
    "\n",
    "Một kiến trúc hợp lý:\n",
    "\n",
    "- PostgreSQL: lưu dữ liệu chuẩn hóa, đảm bảo tính nhất quán & audit.\n",
    "- Một ETL / replication pipeline:\n",
    "  - đọc từ Postgres (hoặc từ hệ thống DICOM),\n",
    "  - đẩy sang Elasticsearch (text reports + image vectors),\n",
    "  - phục vụ các UI search / analytics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbms-assignment (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
